\subsection{Topology from monogenics}

One of the main theorems we prove is as follows.

\begin{theorem}
For any $\mu \in \characters$, there is a point $x^\mu \in \ball$ such that $\mu = \delta_{x^\mu}$. The map
\[
\gamma \colon \characters \to \ball, \quad \mu \mapsto x^\mu
\]
is a homeomorphism, so that $\characters \cong \ball$. The Gelfand transform
\[
\Gamma \colon \monogenics \to C(\characters; \spinalgebra), \quad (\Gamma f)(\mu) \coloneqq \mu(f), \quad \mu \in \characters,
\]
is an isometry onto its image, so that $\characters \cong \Gamma(\monogenics)$.
\end{theorem}

We prove this theorem in two main parts. 

\begin{enumerate}[1.]
    \item Construct a representation of monogenic $(0+2)$-vectors as power series of $B$-planar monogenics.
    \item We constructively show a correspondence between $\mu \in \characters$ with $x^\mu \in \ball$.  
\end{enumerate} 

\subsubsection{Power series}
\textcolor{red}{Define the cauchy kernel and celebrated cauchy integral formula because it is a nifty reason to use clifford algebra.}
Here we prove the statment: \textcolor{red}{Actually, we replace this statement with a power series representation}
\begin{lemma}
We have that
\[
\overline{\Span \{ \algebra{B} ~\vert~ \omega \in \Grassmannian{2}{n} \}} = \monogenics.
\]
(Lemma 1 from B.V.) \textcolor{red}{I think this should be stated differently now. This is really like an module generated by algebras since we are multiplying the $B$-axials.}
\end{lemma}
\begin{proof}~
For sake of simplicity, we let $e_1,\dots, e_n$ be an arbitrary basis for $\R^n$.  
\begin{itemize}
    \item Consider the function $z_{B_\sigma(j)}(x)=x_{\sigma(j)} - x_1 e^1 e_{\sigma(j)}$ for $\sigma \in \{2,\dots,n\}$ a permutation.  Note that $z_{B_\sigma(j)}$ is $B_{\sigma(j)}$-planar with $B_{\sigma(j)}=e^1 e_{\sigma(j)}$.  Moreover, $z_{B_\sigma(j)}$ is monogenic as
    \[
        \grad z_{B_\sigma(j)} = e_{\sigma(j)} - e_1 e^1 e_{\sigma(j)} = 0.
    \]
    We denote as well $B_{\sigma(j)} = e^1 e_{\sigma(j)}$.
    \item Let $f \in \monogenics$.  Then by Theorem 4 in \cite{ryan_left_1986}, we have the monogenic polynomials
    \[
        P_{j_2 \dots j_n}(x) = \frac{1}{j!} \sum_{\textrm{permutations}}z_{B_\sigma(1)}(x) \cdots z_{B_\sigma(j)}(x),
    \]
    which generate $f$ as a power series as
    \[
        f(x) = \sum_{j=0}^\infty \left(\sum_{{j_2 \cdots j_n}_{j_2 + \cdots j_n = j}} P_{j_2 \cdots j_n} (x) a_{j_2 \cdots j_n}\right),
    \]
    where
    \[
        a_{j_2 \cdots j_n} = \frac{1}{\omega_n} \int_{\partial \Sigma} \nabla_{e_2}^{j_2} \cdots \nabla_{e_n}^{j_n} G(y) \nu(y) f(y) d \Sigma(y),
    \]
    where $G(y)$ is the Cauchy kernel.
\end{itemize}
\end{proof}

In general, fix an orthonormal basis $e_1,\dots,e_n$ in $\R^n$ and we can define the functions $z_j^i = x^j - x^i e_i e_j$. Recall that for an orthonormal basis the reciprocal basis elements $e^i=e_i$. To further condense notation, we let $B_{ij}=e_i e_j$ be the 2-blade acting as the pseudoscalar for the $e_i e_j$-plane. In the same vein, the functions $z_j^i$ are very analogous to $z$ in $\C$ but rather in the $B_{ij}$ plane.  One can note
\[
z_j^i = x^j - x^i B_{ij} = x \cdot e_j - x\cdot e_i B_{ij} = e_j(\projection{e_j}{x} + \projection{e_i}{x}).
\]




\subsubsection{Correspondence}

The functions $z_j^i$ play a crucial role in the above power series representation but they also play a key part in determining the behavior of the spin characters $\mu \in \characters$.  If we are able to deduce the action $\mu(z_j^i)$, then we can extend this to any monogenic $f$ via the power series representation. Note that for any $\mu \in \characters$ that $\mathbb{A}_B=\mu(\algebra{B})$ is a commutative subalgebra of $\mathfrak{spin}(n)$.  In particular, for a constant $c \in \algebra{B}$, $\mu(c)=c$ and so we retrieve $\mathbb{A}_B$ must be generated by scalars and the bivector $B$.  Thus, $\mathbb{A}_B$ is an isomorphic copy of $\mathfrak{spin}(2)$ as the algebra of the $B$-plane. \textcolor{red}{Note that $\mu$ will be constant on $2$-blades.}

Working with the same orthonormal basis and applying $\mu$ yields
\[
\mu(z_j^i) = a_j^i + b_j^i B_{ij},
\]
for some constants $a_j^i$ and $b_j^i$.  The $z_j^i$ are not independent from one another.  In fact, we have two key relationships in that
\begin{equation}
\label{eq:z_reciprocal_relationship}
z_j^i B_{ij}  = z_i^j.
\end{equation}
Similarly, we have
\begin{equation}
\label{eq:z_relationship}
z_j^i = B_{jk} z_j^k B_{kj} - z_i^k B_{ij}.
\end{equation}
We simply compute the above,
\begin{align*}
B_{jk} z_j^k B_{kj} - z_i^k B_{ij} &= B_{jk} (x^j-x^k B_{kj}) B_{kj} - (x^i -x^k B_{ki}) B_{ij}\\
    &= x^j -x^k B_{kj} -x^i B_{ij} +x^k B_{kj}\\
    &= z_j^i.
\end{align*}

Thus, we can take $\mu$ of Equations \ref{eq:z_reciprocal_relationship} and \ref{eq:z_relationship}. First, 
\[
\mu(z_i^j) = \mu(z_j^i B_{ij}) = \mu(z_j^i) B_{ij}
\]
yields
\[
a_i^j - b_i^j B_{ij} = -b_j^i + a_j^i B_{ij}
\]
and so $a_i^j = b_j^i$ for all $i \neq j$. Next,
\[
\mu(z_j^i) = \mu(B_{jk} z_j^k B_{kj} - z_i^k B_{ij}) = B_{jk} \mu{z_j^k} B_{kj} - \mu(z_i^k) B_{ij}
\]
and so
\[
a_j^i + b_j^i B_{ij} = B_{jk} (a_j^k +b_j^k B_{kj}) B_{kj} - (a_i^k + b_i^k B_{ki}) B_{ij} = a_j^k - a_i^k B_{ij}
\]
yields $a_j^i = a_j^k$ and $a_i^k=-b_j^i$. In particular, for all $z_j^i$, we have the relationships
\[
a_i^j =- b_j^i, \quad a_j^i = a_j^k, \quad a_i^k =- b_j^i, \quad \textrm{for $i\neq j \neq k$.}
\]
More simply, we can note 
\[
a_i^\bullet = - b_\bullet^i ~\forall i \qquad \textrm{and} \qquad  a_j^\bullet = a_j^\bullet ~\forall j.
\]
Letting $\mu(z_j^i) = z_j^i(x_\mu)$ satisfies these requirements above since $z_j^i(x_\mu) = x_\mu^j - x_\mu^i B_{ij}$ for all $i\neq j$. 
\textcolor{red}{Make the matrix argument and stuff then show that the point itself must also be in $\ball$.}



