\subsection{Clifford algebras}
The complex algebra $\C$ can be generalized in a handful of ways.  Some of which can be found through the use of Clifford algebras and, more specifically, in geometric algebras.  We define the more general Clifford algebras first and realize geometric algebras as particularly nice Clifford algebras with a quadratic form arising from an inner product. Elements of a geometric algebra are known as multivectors and these multivectors carry a wealth of geometric information in their algebraic structure. $\C$ itself can be realized as a special subalgebra of biparavectors in the geometric algebra on $\R^2$ with the Euclidean inner product and the quaternions $\quat$ are realized as an analogous algebra on $\R^3$. In particular, both $\C$ and $\quat$ arise as the 2- and 3-dimensional even Clifford groups $\Gamma^+$ respectively.

Formally, we let $(V,Q)$ be an $n$-dimensional vector space $V$ over some field $K$ with an arbitrary quadratic form $Q$.  The tensor algebra is given by
\[
\mathcal{T}(V) \coloneqq \bigoplus_{j=0}^\infty V^{\otimes j} = K \bigoplus V \oplus (V\otimes V) \oplus (V\otimes V \otimes V) \oplus \cdots,
\]
where the elements (tensors) inherit a multiplication $\otimes$ (the tensor product). From the tensor algebra $\mathcal{T}(V)$, we can quotient by the ideal generated by $v\otimes v - Q(v)$ to define \emph{Clifford algebra} $C\ell(V,Q)$. That is, 
\[
C\ell(V,Q) = \mathcal{T}(V) ~ / ~ \langle v \otimes v - Q(v) \rangle.
\]
To see how the tensor product descends to the quotient, we let $e_1, \dots, e_n$ be an arbitrary basis for $V$, then we can consider the tensor product of basis elements $e_i \otimes e_j$ which induces a product in the quotient $C\ell(V,Q)$ which we refer to as the \emph{Clifford multiplication}. In this basis, we write this product as concatenation $e_ie_j$ and define the multiplication by
\[
e_i e_j = \begin{cases} Q(e_i) & \textrm{if $i=j$}, \\ e_i \wedge e_j & \textrm{if $i\neq j$},\end{cases}
\]
where $\wedge$ is the typical exterior product satisfying $v\wedge w = - w\wedge v$ for all $v,w\in V$.  As a consequence, the exterior algebra $\bigwedge(V)$ can be realized as a subalgebra of any Clifford algebra over $V$ or as a Clifford algebra with a trivial quadratic form $Q=0$.  

Note that $C\ell(V,Q)$ is a $\mathbb{Z}$-graded algebra with elements of grade-0 up to elements of grade-$n$. We refer to grade-0 elements as scalars, grade-1 elements as vectors, grade-2 elements as \emph{bivectors}, grade-$k$ elements as \emph{$k$-vectors}, and grade-$n$ elements as \emph{pseudoscalars}. We denote the space of $k$-vectors by $C\ell(V,Q)^k$. For each grade there is a basis of ${n\choose k}$ \emph{$k$-blades} which are $k$-vectors of the form
\[
A_k = \prod_{j=1}^k v_j, ~\textrm{for}~ v_j \in V.
\]
For example, if $\dim(V)=3$, then there are ${3\choose 2}=3$ 2-blades that form a basis for the bivectors. One particular choice given our vector basis of $V$ would be the following list of 2-blades
\[
\label{eq:3_dim_basis}
B_{12} = e_1 \wedge e_2, \quad B_{13} = e_1 \wedge e_3, \quad B_{23} = e_e \wedge e_3.
\]
We refer to an $(n-1)$-blade as a \emph{pseudovector} and it should be noted that every $(n-1)$-vector is a pseudovector. In other literature, some will refer to a $k$-blade as a \emph{simple} or a \emph{decomposable} $k$-vector. 

In general, an element $A \in C\ell(V,Q)$ is written as a linear combination of basis elements of all possible grades and we refer to $A$ as a \emph{multivector}.  To extract the grade-$k$ components of $A$, we use the notation
\[
\proj{k}{A}
\]
to denote the grade-$k$ components of the multivector $A$. Any multivector $A$ can then be given by
\[
A = \sum_{k=0}^n \proj{k}{A}
\]
which shows the decomposition
\[
C\ell(V,Q) = \bigoplus_{j=0}^n C\ell(V,Q)^j.
\]
For example, $A\in C\ell(\R^3, \|\cdot \|)$ is given by
\[
A= a + \alpha_1 e_1 + \alpha_2 e_2 + \alpha_3 e_3 + \beta_{12} B_{12} + \beta_{13} B_{13} + \beta_{23} B_{23} + r e_1 \wedge e_2 \wedge e_3
\]
in general, and we have
\[
\proj{0}{A}=a, \quad \proj{1}{A}=\alpha_1 e_1 + \alpha_2 e_2 + \alpha_3 e_3, \quad \proj{2}{A}=\beta_{12} B_{12} + \beta_{13} B_{13} + \beta_{23} B_{23}, \quad \proj{3}{A} = re_1 \wedge e_2 \wedge e_3.
\]
If $A$ contains only grade-$k$ components, then we say that $A$ is \emph{homogeneous}.  For example, when we refer to vectors we realize them as homogeneous grade-1 multivectors and likewise we realize bivectors as homogeneous grade-2 multivectors. We also refer elements in
\[
 C\ell(V,Q)^{0+2} = C\ell(V,Q)\oplus C\ell(V,Q)^2
\]
as \emph{biparavectors}.

The Clifford multiplication of vectors can be extended to multiplication of vectors with homogeneous grade-$k$ multivectors.  In particular, given a vector $v \in C\ell(V,Q)$ and a homogeneous grade-$k$ multivector $A_k \in C\ell(V,Q)$, we have
\begin{equation}
\label{eq:vector_multiplication}
aA_k = \proj{k-1}{aA_k} + \proj{k+1}{aA_k},
\end{equation}
which decomposes the multiplication into a grade lowering \emph{interior product} and a grade raising \emph{exterior product}.  This allows us to extend the Clifford multiplication further. Given a homogeneous grade-$s$ multivector $B_s$, we have
\begin{equation}
\label{eq:general_clifford_multiplication}
A_k B_s = \proj{|r-s|}{A_rB_s} + \proj{|r-s|+2}{A_rB_s} + \cdots + \proj{r+s}{A_rB_s}.
\end{equation}
This rule for multiplication then allows for the multiplication of two general multivectors in $C\ell(V,Q)$. 

Some specific graded elements of the above product are worth noting here, 
\begin{equation}
    A_k \cdot B_s \coloneqq \proj{|k-s|}{A_k B_s}
\end{equation}
\begin{equation}
    A_k \wedge B_s \coloneqq \proj{k+s}{A_k B_s}
\end{equation}
\begin{equation}
\label{eq:left_contraction}
    A_k \rfloor B_s \coloneqq \proj{s-k}{A_k B_s}
\end{equation}
\begin{equation}
\label{eq:right_contraction}
    A_k \lfloor B_s \coloneqq \proj{k-s}{A_k B_s}.
\end{equation}
These products are particularly emphasized as many helpful identities used in this paper are phrased using these notions. Another key reason behind the additional multiplication symbols $\rfloor$ and $\lfloor$ is to avoid needing to pay special attention to the specific grade of each multivector in a product.  The product $\cdot$ on $A_k$ and $B_s$ depends on $k$ and $s$ and as such given by either $\rfloor$ or $\lfloor$ but one must know $k$ and $s$ in order to define this product exactly. 

We also have the identities
\begin{equation}
\label{eq:left_contraction_dot}
A_r \cdot B_s = A_r \rfloor B_s \qquad \textrm{if $k\leq s$}
\end{equation}
\begin{equation}
\label{eq:right_contraction_dot}
A_r \cdot B_s = A_r \lfloor B_s \qquad \textrm{if $k\geq s$}.
\end{equation}
For homogeneous $k$-vectors $A_k$ and $B_k$, the products above simplify to 
\begin{equation}
\label{dot_equivalent_contraction}
    A_k \lfloor B_k = A_k \rfloor B_k = A_k \cdot B_s.
\end{equation}
Using this notation, for a vector $\alpha$ we have
\begin{equation}
\alpha A_k = \alpha \rfloor A_k + \alpha \wedge A_k,
\end{equation}
so the $\cdot$ and $\lfloor$ notation coincide for left multiplication by vectors. If we are given two $k$-blades $A_k = \alpha_1 \wedge \cdots \wedge \alpha_k$ and $B_k = \beta_1 \wedge \cdots \wedge \beta_k$ we have 
\begin{equation}
\label{eq:dot_product}
A_k \cdot B_k^\dagger = \det(\alpha_i \cdot \beta_j )_{i,j=1}^k,
\end{equation}
which is equivalent to $A_k \rfloor B_k$ and $A_k \lfloor B_k$ through \ref{dot_equivalent_contraction} and this is extended to all $k$-vectors as is typically seen when constructing the inner product of $k$-vectors (see \cite{hestenes_clifford_1986}. If we are given two bivectors $B$ and $B'$, then we have another special multiplication
\begin{equation}
\label{eq:bivector_product}
B\times B' \coloneqq \proj{2}{BB'} = \frac{1}{2} (BB' - B'B),
\end{equation}
which is the grade preserving anti-symmetric portion of the product $BB'$.

As discussed, $C\ell(V,Q)$ is naturally a $\mathbb{Z}$-graded algebra but we also find that it carries a $\mathbb{Z}/2\mathbb{Z}$-grading as well. This additional grading can be realized by sorting $k$-vectors in $C\ell(V,Q)$ into the sets where $k$ is even or odd.  We say a $k$-vector is \emph{even} (resp. \emph{odd}) $k$ is even (resp. odd) and in general if a multivector $A$ is a sum of only even (resp. odd) grade elements we also refer to $A$ as even (resp. odd).  Taking note of the multiplication defined in \ref{eq:general_clifford_multiplication}, one can see that the multiplication of even multivectors with another even multivectors outputs an even multivector.  Thus, the even multivectors form closed subalgebra of $C\ell(V,Q)$ which we denote by $C\ell(V,Q)^+$.

\begin{example}
\label{ex:complex_representation}~
\begin{itemize}
    \item Let $V=\R^2$ and let the quadratic form $Q$ be given by the Euclidean norm $Q(\cdot)=\|\cdot\|$.  Let $e_1$ and $e_2$ be the standard unit vectors and note that we have $1$ as the basis scalar, and $B_{12} = e_1\wedge e_2 = e_1e_2$ as the basis pseudoscalar.  Thus, a general multivector $m$ and $r$ can be written as
\[
m = m_0 + m_1 e_1 + m_2 e_2 + m_{12} B_{12}, \qquad r = r_0 +r_1 e_1 + r_2 e_2 + r_{12}B_{12}.
\]
We can then multiply $mr$ and find
\[
\proj{0}{mr} = m_0r_0 + m_1 r_1 + m_2 r_2 - m_{12}r_{12},
\]
\[
\proj{1}{mr} = (m_0 r_1 + m_1 r_0 - m_2 r_{12} + m_{12} r_2) e_1 + (m_0 r_2 + m_2 r_0 + m_1r_{12} - m_{12} r_1) e_2,
\]
and
\[
\proj{2}{mr} = (m_1r_2 - m_2 r_1)B_{12}.
\]

Most notably, we see that $B_{12}^2=-1$ and this allows us to consider a biparavector
\[
z = x + y B_{12} 
\]
as a representation of the complex number $\zeta = x+ iy$ in $\G_n^{0+2}$.  Thus, the even subalgebra of this Clifford algebra is indeed isomorphic to the complex numbers $\C$. 

    \item If $V =\R^n$, with $n\geq 2$, and with the analogous $Q$, then there are natural copies of $\C$ contained inside of $C\ell(V,Q)$. In particular, we have the isomorphism
    \[
        \C \cong \{\lambda + \beta B ~\vert~ \lambda,\beta \in C\ell(V,Q)^0,~ B \in C\ell(V,Q)^2,~ B^2=-1. \},
    \]
   which shows that complex numbers arise as biparavectors. Given the standard basis $e_1,\dots,e_n$ we have copies of $\C$ for each of the ${ n \choose 2}$ unit bivectors $B_{jk}$ with $k=2,\dots,n$ and $j<k$. Note that $B_{jk}B_{jk}=-1$ and we have the representation of $\C$ since
    \[
        \zeta = x + yB,
    \]
    behaves as a complex number $z=x+iy$.
\end{itemize}
\end{example}

\begin{example}
\label{ex:quaternions}
Let $V=\R^3$ and $Q(\cdot)=\|\cdot \|$.  Then, let
\[
B_{23} = e_2 e_3, \quad B_{31} = e_3 e_1, \quad B_{12} = e_1 e_2,
\]
and note that we can write a even multivector as
\[
q = a + \beta_{23} B_{23} + \beta_{31} B_{31} + \beta_{12} B_{12}.
\]
Note as well that
\[
B_{23}^2 = B_{31}^2 = B_{12}^2 = -1,
\]
and
\[
B_{23}B_{31}B_{12} = +1.
\]
In this case, this even subalgebra is extremely close to being a copy of the quaternion algebra $\quat$. Indeed, one can arrive at a representation of the quaternions by taking
\[
\boldsymbol{i} \leftrightarrow B_{23}, \quad \boldsymbol{j} \leftrightarrow -B_{31}=B_{13}, \quad \boldsymbol{k} \leftrightarrow B_{12},
\]
and noting that we then have $ijk=-1$ as well as $i^2=j^2=k^2=-1$. A more in depth explanation is provided in \cite{doran_geometric_2003}.

Once again, quaternions arise naturally as parabivectors since we can put
\[
q= \alpha + u_1B_{23} - u_2 B_{13} + u_3 B_{12},
\]
and recover the necessary arithmetic seen in $\quat$.
\end{example}

In the case where $V$ has a (pseudo) inner product $g$, we can induce a quadratic form $Q$ by $Q(v)=g(v,v)$ and give rise to a Clifford algebra $C\ell(V,Q)$.  This is a special case and we refer to this type of Clifford algebra as a \emph{geometric algebra}. We generally put $\geometricalg$ and assume the inner product will be given alongside or will be clear from context.  For example, when $V=\R^n$ and we define $Q$ from the Euclidean inner product, we have $C\ell(V,Q)=\mathcal{G}(\R^n)$ and moreover we put $\mathcal{G}(\R^n)=\mathcal{G}_n$. For more information on the topic of geometric algebras see the classical text \cite{hestenes_clifford_1986} or the text \cite{doran_geometric_2003} which also provides a wide range of applications to physics problems. Both these sources include much of the other necessary preliminaries I cover in the remainder of this section. Finally, the paper \cite{chisolm_geometric_2012} proves many of the useful identities I claimed above.

\begin{example}
\label{ex:spacetime_algebra}
If instead we take $V=\R^4$ we take the vector basis $e_t,e_1,e_2,e_3$ with the pseudo inner products
\[
e_t \cdot e_t = -1 \qquad e_t \cdot \gamma_i =0 ~i=1,2,3, \quad e_i \cdot e_j =\delta_{ij}.
\]
For this basis, we can denote the matrix for this inner product $\eta =\operatorname{diag}(-+++)$ and define $Q$ from $\eta$. Then, we have for a vector $A = A_t e_t +A_1 e_1 + A_2 e_2 + A_3 e_3$ we have
\[
A\cdot A = -A_t^2 + \sum_{i=1}^3 A_i^2.
\]
\end{example}

For the cases with pseudo inner products with $p$ vectors satisfying $e_i^2 = -1$ for $i=1,\dots, p$ and $q$ vectors satisfying $e_j^2=1$ for $q=p+1,\dots,p+q$, we will denote the algebras by $\G_{p,q}$.

\subsubsection{Duality and pseudoscalars}
\label{subsection:duality_and_pseudoscalars}

For the remainder of this paper we will be working with geometric algebras with a positive definite inner product $g$. Given access to an inner product we have a natural isomorphism between $V$ and $V^*$ by the Riesz representation.  Namely, given an arbitrary basis $e_i$ for $V$ there exists the dual basis $f_i$ for $V^*$ such that $f_i(e_j)=\delta_{ij}$.  This dual basis resides inside $V$ itself in the following manner. There is then a unique map $\sharp \colon V^* \to V$ with $f\mapsto f^\sharp$ such that
\[
f_i^\sharp \cdot e_j = \delta_{ij},
\]
where $\delta_{ij}$ is the Kronecker delta symbol. In terms of the geometric algebra, we put $e^i \coloneqq f_i^\sharp$ and can note that $e^i$ is simply a vector in the geometric algebra. For an arbitrary basis $e_1,\dots,e_n$ for $V$, the coefficients for the inner product $g$ are given by $g_{ij}=e_i\cdot e_j$ and we can put $e^i = g^{ij}e_j$ where $g^{ij}$ is the coefficients to matrix inverse of $g_{ij}$.  There is inverse isomorphism $\flat \colon V \to V^*$ given by $e \mapsto e^\flat$ satisfying
\[
e_i^\flat (e_j)= \delta_{ij}.
\]
Given these identifications, there is no need to distinguish between the vector space $V$ and its dual $V^*$ as it suffices to consider $V$ itself with reciprocal basis elements $e^i$ with the application of the scalar product.

A volume element can be defined by $\mu=e_1 \wedge e_2 \wedge \cdots \wedge e_n = \sqrt{|g|} I$ where $\sqrt{|g|}$ is the square root of the determinant of the matrix $g_{ij}$ and $I$ is the unit pseudoscalar. It follows that the unit pseudoscalar is given by $I=\frac{1}{\sqrt{|g|}} e_1 \wedge e_2 \wedge \cdots e_n$. We can define $\mu^{-1}$ such that $\mu^{-1}\mu = 1 = \mu \mu^{-1}$ and analogously $I^{-1}$.  One can equivalently put $e^j = (-1)^{j-1} e_1 \wedge e_2 \wedge \cdots \wedge \breve{e_j} \wedge \cdots \wedge e_n \mu^{-1}$ and note that this gives $\mu^{-1} = e^n \wedge \cdots \wedge e^1$.  Conveniently, the unit pseudoscalar satisfies the relation
\[
IA_k = (-1)^{k(n-1)} A_k I.
\]
Thus, $I$ commutes with the even subalgebra, and anticommutes with the odd subalgebra.  Moreso, the pseudoscalar allows one to exchange the interior and exterior products as
\begin{equation}
\label{eq:wedge_to_dot}
 (A_k \wedge B_s) I = A_k \cdot (B_s I)
\end{equation}
for homogeneous $k$ and $s$-vectors $A_k$ and $B_s$. The above holds true if we replace $I$ with $I^{-1}$ when working in spaces where $g$ is positive definite due to the fact that $I^{-1}$ differs only by a sign. If $B_s = C_{n-s}I$ then,
\begin{align*}
 (A_k \cdot B_s)I^{-1} = A_k \cdot (C_{n-s}I) = (A_k \wedge C_{n-s})I = (A_k \wedge (B_sI))I,
\end{align*}
and in particular
\begin{equation}
\label{eq:dot_to_wedge}
    (A_k \cdot B_s)I^{-1} = A_k \wedge (B_s I).
\end{equation}
This shows the duality between the inner and exterior products. The duality extends further to provide an isomorphism between the spaces of $k$-vectors and $(n-k)$-vectors. For any $k$-vector $A_k$, we can take $A_k I^{-1}=B_{n-k}$ to get the corresponding $(n-k)$-vector $B_{n-k}$. It is under this isomorphism one can see that all pseudovectors are $(n-1)$-blades. 

\begin{example}
\label{ex:cross_product}
Consider $\spacealg$ with the standard orthonormal vector basis $e_1,\dots,e_n$ and Euclidean inner product.  Then, we can define the \emph{cross product} of two vectors $u$ and $v$ by
\[
u \times v = (u\wedge v)I^{-1}.
\]
The special fact of $\spacealg$ is that vectors and bivectors (pseudoscalars in 3-dimensions) are dual to one another. One can also note that the vector $w=u\times v$ is sometimes refered to as axial and in other cases the pseudovector $u\wedge v$ is referred to as axial. 

The $\times$ symbol is now overloaded from the bivector definition we saw prior to this example.  But, referring back to Example \ref{ex:quaternions}, we can realize the cross product of vectors as the antisymmetric product of bivectors
\[
(uI^{-1})\times (vI^{-1}). 
\]
The necessary relationships for the cross product are seen clearly on the products of the basis blades $B_{23}, B_{31}$, and $B_{12}$. In particular, $e_1 = B_{23}I^{-1}$, $e_2 = B_{31} I^{-1}$, and $e_3 = B_{12} I^{-1}$.
\end{example}

\subsubsection{Reverse, inverses, and the Clifford and spin groups}

We had used the notation $~^{-1}$ to denote the inverse for the pseudoscalar, but there are other invertible elements in a geometrical algebra.  In particular, all blades are invertible. From this, we can construct a group of all invertible elements referred to as the \emph{Clifford group} $\Gamma$ for a geometric algebra $\G$ by
\[
\Gamma \coloneqq \left\{ \prod_{j=1}^k v_i ~\vert~ k\in \mathbb{Z}^+,~ \forall j~\colon1\leq j \leq k~\colon~v_i \in \R^n ~\textrm{such that}~|v_i|\neq 0\right\}.
\]
We refer to elements of the Clifford group as \emph{Clifford multivectors}. For any Clifford multivectors $A = v_1 \cdots v_k$ in the group $\Gamma$, we have that multiplicative inverse $A^{-1}$ is given by $A^{-1} = v^k \dots v^1$ as we can see that $A^{-1}A=AA^{-1} = 1$ by construction.  Of note is the fact that all scalars, vectors, pseudovectors, and pseudoscalars are always in the Clifford group and have multiplicative inverses. The inverse of a vector $v$ is given by $\frac{v}{v\cdot v}$. It becomes useful to define the \emph{reverse} $\dagger$ such that $A^\dagger = v_k \cdots v_1$. For a $k$-blade $A_k$, the reverse also satisfies the relationship
\begin{equation}
\label{eq:reverse_sign}
A_k^\dagger = (-1)^{k(k-1)/2} A_k.
\end{equation}
One can then see that the inverse for the unit pseudoscalar is $I^{-1}=I^\dagger$ which is an identification I will often use. One can see that the multiplicative inverse of an element of the Clifford group $A$ is the reverse of the corresponding product of reciprocal vectors since $A_k^{-1} = (v^1 \cdots v^k)^\dagger$. Note as well that elements $s \in \Gamma^+$ act as rotations on $A\in \G_n$ given the conjugate action
\[
A \mapsto s A s^{-1}.
\]
In fact, all nonzero vectors $v\in\Gamma$ define a reflection in the hyperplane perpendicular to $v$ via the same conjugation action above.

Following these realizations, one can see that the Clifford group contains important subgroups such as the orthogonal and special orthogonal groups as quotients
\[
\operatorname{O}(n) \cong \Gamma/\R \qquad \textrm{and} \qquad \operatorname{SO}(n) \cong \Gamma^+ /\R.
\]
This motivatives the following definition.
\begin{definition}
    The \emph{Clifford norm} $\| \cdot \|$ for $s \in \Gamma$ is given by
    \[
    \|s\|^2 \coloneqq ss^\dagger.
    \]  
\end{definition}
Note that for vectors the Clifford norm corresponds with the norm induced from the inner product in that with a vector $v$ we have $\|v\|=vv^\dagger = v\cdot v$. We also give the name \emph{unit} to $k$-blades $A_k$ with unit spinor norm $1=\|A_k\|$. We can also see that 
\begin{equation}
\label{eq:pseudoscalar_norm}
\|\mu\| = \sqrt{|g|},
\end{equation}
and so
\[
\|I\| = 1.
\]

With this, we have the \emph{pin} and \emph{spin groups}
\begin{align*}
    \operatorname{Pin}(n) &\coloneqq \{s\in \Gamma ~\vert~ \|s\|=1\}.\\
    \operatorname{Spin}(n) &\coloneqq \{s\in \Gamma^+ ~\vert~ \|s\|=1\}.
\end{align*}
Moreover,
\[
\operatorname{Pin}(n) \cong \Gamma/\R^+ \qquad \textrm{and} \qquad \operatorname{Spin}(n) \cong \Gamma^+/\R^+.
\]

The spin group $\spingroup$ is a Lie group and its associated Lie algebra is denoted by $\spinalgebra$. In particular, the $\spinalgebra$ is isomorphic to the algebra of bivectors with the antisymmetric product $\times$ \todo[inline]{provide a citation.}.  Then, for any bivector $B$, we have an element in the spin group given by
\[
e^{B} = \sum_{j=0}^\infty \frac{B^n}{n!}.
\]
Fundamentally, $\spingroup$ acts on the even subalgebra $\G_n^+$. A \emph{spinor} $\psi$ is an element that transforms under a left action of an element of $\spingroup$ to produce another spinor.  In terms of geometric algebra, a spinor is simply an even multivector (i.e., an element of $\G_n^+$).  Of note are the two cases we have had as examples before. 

\begin{example}
\label{ex:exponential_of_bivector}
    Consider $\G_2$ and note that we have shown the algebra of spinors $\G_2^+$ is isomorphic to the complex numbers $\C$.  Indeed, there is one unit 2-blade $B_{12}$ in $\G_2$ to form the spin algebra $\mathfrak{spin}(2) \cong \R$ and as a consequence all unit norm elements in $\G_2^+$ can be written as
    \[
       e^{\theta B_{12}} = \sum_{n=0}^\infty \frac{\theta B_{12}}{n!} = \cos(\theta)+B_{12}\sin(\theta),
    \]
    where $\theta B_{12}$ is a general bivector in $\G_2$.  Hence, we arrive at $\operatorname{Spin}(2)\cong \operatorname{U}(1)$. Any element in $\C$ is also a scaled version of an element of the spin group $\operatorname{Spin}(2)$. Hence, we can use a spin representation for an element in $\C$ via $z=re^{\theta B_{12}} \in \R\times \operatorname{Spin}(2)$.  This special case shows that parabivectors in $\G_2$ have a unique spin representation and they are spinors as well.
\end{example}

\begin{example}
    Consider $\G_3$ and note that we have shown the spinors $\G_3^+$ are isomorphic to the quaternion $\quat$ algebra.  We also realize $\quat$ as scalar copies of elements of $\operatorname{Spin}(3) \cong \operatorname{Sp}(1)$.  That is to say that $\quat \cong \R \times \operatorname{Spin}(3)$. Indeed, since elements of $\G_3^+$ are simply biparavectors, the biparavectors once again admit a natural spin representation. Likewise, \todo[inline]{finish this.}
\end{example}

\subsubsection{Projection and rejection}

There is a direct relationship between unit $k$-blades and $k$-dimensional subspaces.  Indeed, each unit $k$-blade $B_k$ ($\|B_k\|=1$) corresponds to a $k$-dimensional subspace.  That is, each point in $\Grassmannian{k}{n}$ corresponds to a unit $k$-blade.  Since blades represent subspaces, they also give us a compact way of projecting multivectors into subspaces.  In general, given an multivector $A$ the \emph{projection} onto the subspace spanned by $B_k$ is
\begin{equation}
\label{eq:projection}
\projection{B_k}{A} \coloneqq (A\rfloor B_k)B_k^{-1}.
\end{equation}
By definition, we have
\[
\projection{B_k}{A} \in \bigoplus_{j=0}^k \G_n^j = \G_n^{0+\cdots + k}
\]
Specifically,
\[
\projection{B_k}{\proj{j}{A}} \in G_n^j,
\]
shows the projection preserves grades.

G a vector $v$, the projection onto the subspace spanned by the $k$-blade $A_k$ is given by the identity
\begin{equation}
\label{eq:vector_projection}
(v\rfloor A_k )A_k^{-1} = (v\rfloor A_k)\rfloor A_k^{-1} = (v\cdot B_k)\cdot B_k^{-1}.
\end{equation}
and more enlightening is to take a projection of a vector $v$ onto another vector $u$
\[
(v\rfloor u)u^{-1} = (v \cdot u) \frac{u}{\|u\|^2},
\]
which is the expected result. 

A dual notion also exists.  We define the \emph{rejection} of a multivector from the subspace spanned by $B_k$ as
\begin{equation}
\label{eq:rejection}
\rejection_{B_k}(A) = (A\wedge B_k)B_k^{-1}.
\end{equation}
In the case we have a vector $v$, we can note
\begin{equation}
\label{eq:projection+rejection_vector}
\projection{B_k}{v} + \rejection_{B_k}(v) = v.
\end{equation}

To see this in action, we let $v=v^1 e_1 + v^2 e_2 + v^3 e_3$ and let $B_{12}=e_1 e_2$ and note
\begin{align*}
    \rejection_{B_{12}}(v) &= [(v^1 e_1 + v^2 e_2 + v^3 e_3)\wedge (e_1 e_2)]B_{12}^{-1}\\
    &= v^3 e_3 e_1 e_2 e^2 e^1 \\
    &= v^3 e_3.
\end{align*}
Both the notion of projection and rejection prove to be useful. For vectors $u$ and $v$, we can find
\begin{equation}
\label{eq:projection_rejection_vector}
\projection{uI^{-1}}{v} = \rejection_u(v).
\end{equation}

\todo[inline]{Change the above equation slightly for the use in the Calderon section. Can we use rejection to simplify the $B$-planar proofs}


\subsection{Multivector fields}

We want to generalize the setting of geometric algebra to include a smooth structure. One can take the work above for $\mathcal{G}_n$ and consider a $C^{\infty}$-module structure as opposed to the $\R$-algebra structure in the proceeding section. For brevity, we put $\mathcal{G}_n(\R^n)$ for the $C^\infty$-module and $\G_n$ for the $\R$-algebra. The multivectors themselves can be realized as constant multivector fields so that $\G_n \subset \G_n(\R^n)$. This smooth setting simply makes the coefficients of the global basis blades given by $C^\infty$ functions as opposed to $\R$ scalars.  In this case, we refer to a generic element in the $C^{\infty}$-module $\mathcal{G}_n$ as a \emph{multivector field}. We take $\Omega \subset \R^n$ as a connected region in $\R^n$ for the entirety of this paper and we put
\[
\G_n(\Omega) \coloneqq \{ f \colon \Omega \to \G_n ~\vert~ \textrm{$f$ is $C^\infty$-smooth}\},
\]
where smoothness is meant in terms of the $C^\infty$-module structure.

Perhaps the $C^\infty$-module structure obfuscates the point slightly.  Instead, one should think of the fields in $\G_n(\Omega)$ as multivector valued functions on $\Omega \subset \R^n$.  Taking this identification allows for an extended toolbox at our disposal.  In particular, points in $\Omega$ are uniquely identified with constant vector fields in $\G_n^1$ and one can consider endomorphisms living in $\G_n$ (acting on $\G_n^1$) as acting on the input of fields in $\G_n(\Omega)$ as well.  Thus, there is not only an algebraic structure on the fields themselves, but on the point in which the field is evaluated.  This is perhaps the key insight on why authors developed the so-called vector manifolds widely used in the geometric algebra landscape.

\begin{example}
    Consider a multivector field $f$ valued in $\G_n(\R^n)$.  With $x\in \R^n$ being identified with the vector in $\G_n^1$, we output a multivector $f(x) \in \G_n$ at each point $x$.  One may be interested in the restriction of $f$ to a vector subspace of $\R^n$ which amounts to using projection on the input.  For example, perhaps we wish to know how $f$ behaves on the subspace generated by some $k$-blade $A_k$.  As such, it suffices to then study $f(\projection{A_k}{x})$.  
\end{example}

We refer to smooth fields valued in $\G_n^+$ as \emph{spinor fields} and put $\G_n^+(\Omega)$ to refer to the $C^\infty$-module counterpart. These fields will be shown to carry a Banach algebra structure. 


\subsubsection{Directional derivative and gradient}

Note that $\R^n$ has global coordinates and thus we can choose a global constant vector field basis $e_1,\dots,e_n$ and we generate $\G_n$ from this basis. Note that we will adopt the Einstein summation convention when needed. With respect to these fields, we have the \emph{directional derivative} $\nabla_\omega$ with $\omega = \omega^i e_i$. The \emph{gradient} (or \emph{Dirac operator}) is defined as $\grad = \sum_{i} e^i \nabla_{e_i}$ and it acts a grade-1 element in the algebra.   Note then that $\omega \cdot \grad = \nabla_\omega$ defines the directional derivative via the gradient. The directional derivative is also grade preserving in that for a multivector $A$
\[
\nabla_\omega \proj{k}{A} = \proj{k}{\nabla_\omega A}.
\]  

This structure defined above is typically referred to as \emph{geometric calculus}.  The setting for geometric calculus extends the setting of differential forms and reduces some of the complexity with tensor computations.  Since $\grad$ is a grade-1 object, it acts on a homogeneous $k$-vector $A_k$ by
\[
\grad A_k = \proj{k-1}{\grad A_k} + \proj{k+1}{\grad A_k} \coloneqq \grad \cdot A_k + \grad \wedge A_k.
\]
Thus, the gradient splits into two operators $(\grad \cdot) \colon \G_n^k(\Omega) \to \G_n^{k-1}(\Omega)$ (or $\grad \lfloor$) and $(\grad \wedge) \colon \G_n^k \to \G_n^{k+1}$.  Here, $\grad \wedge$ can be identified with the exterior derivative $d$ and $\grad \cdot$ can be identified with the codifferential $\delta$ on differential forms up to a sign (see \cite{schindler_geometric_2020} \textcolor{red}{There are more citations to use}). This of course means the standard properties that apply to $d$ and $\delta$ apply to $\grad \wedge$ and $\grad \cdot$. Namely, we have
\begin{equation}
\label{eq:differential_properties}
(\grad \wedge)^2=0 \qquad (\grad \cdot)^2 = 0,
\end{equation}
when acting on a homogeneous $k$-vector. Since \ref{eq:differential_properties} holds, the gradient operator gives rise to the grade preserving \emph{Laplace-Beltrami operator}
\[
\Delta = \grad \grad = \grad \cdot \grad \wedge + \grad \wedge \grad \cdot,
\]
which is manifestly coordinate invariant by definition.  It also motivates the use of the physicist notation $\grad^2=\Delta$, but we do not adopt this here.  We refer to multivector fields $f$ in the kernel of the Laplace-Beltrami operator \emph{harmonic}.

\subsubsection{Monogenic fields}

Geometric calculus includes another definition for multivectors that is a big motivation for those who study Clifford analysis. 
\begin{definition}
 Let $f \in \G_n(\Omega)$. Then we say that $f$ is \emph{monogenic} if $f \in \ker(\grad)$.
\end{definition}

\todo[inline]{What monogenics are we really caring about here? Just the ones we can recover which are...}
Monogenic fields are of utmost importance as they have many beautiful properties. One should find them as a suitable generalization of the notion of complex holomorphicity. For example, in regions of Euclidean spaces, a monogenic field $f$ can be completely determined by its Dirichlet boundary values through a generalized Cauchy integral formula. For any even monogenic field, the each of the graded components of $f$ are harmonic.  

We put 
\[
\monogenics(\Omega) \coloneqq \{f \in \G_n(\Omega) ~\vert~ \grad f =0\}
\]
to refer to elements of this set as \emph{monogenic fields} on $\Omega$. As a subset, we also have the \emph{monogenic spinors} $\monogenics^+(\Omega)$, which are simply the even monogenic fields and the \emph{monogenic parabivectors} $\monogenics^{0+2}(\Omega)$. Though these spaces do not form algebras in their own right, they do indeed form a vector space as sums of monogenic functions are monogenic due to the linearity of the gradient.  Moreover, the monogenic spinors are invariant under multiplication from the Clifford group $\Gamma^+$.

\begin{lemma}
\label{lem:clifford_invariant}
Let $s\in \spingroup$ then $\grad \circ s = s \circ \grad$.  In particular, the space of monogenic spinors $\monogenics^+(\Omega)$ is $\spingroup$ invariant.
\end{lemma}
This lemma is classical in the theory of the Dirac operator, Clifford analysis, and harmonic analysis so we omit a proof.  One can see \cite{janssens_special_nodate} for example.

\subsection{Differential forms and integration}
\label{subsec:diff_forms}

\subsubsection{Directed measures and $k$-forms}
Naturally, we would also like to be able to integrate multivectors.  In order to do so, we appeal to the language of differential forms and build a relationship between multivectors and forms. Forms have their appeal in global understanding via their properties through integration (e.g., Stokes' and Green's theorems).  What we build here provides us a way to carry out a full multivector treatment of boundary value problems.

Given the coordinate system $x^i$ on $\R^n$, we form the basis of tangent vector fields $\partial_i = \frac{\partial}{\partial x^i}$ with the reciprocal 1-forms $dx^i$ (a section of $T^*\Omega$) which are the differentials of the coordinate functions.  Thinking of 1-forms as linear functions on tangent vectors, we have $dx^i  (\partial_j) = \delta^i_j$.  The benefit of this definition is that the 1-forms $dx^i$ carry a natural measure and we can form product measures via the exterior product.  For example, we have the surface \emph{directed measure} $d\Sigma = e_i \wedge e_j dx^i dx^j$ and we can note that $(e^j \wedge e^i)\cdot d\Sigma = dx^idx^j - dx^j dx^i$ is antisymmetric and provides us a surface measure we can integrate; this is a differential form.

In an $n$-dimensional space with a position dependent inner product $g$, we have the $n$-dimensional volume directed measure $d\Omega = \sqrt{|g|} dx^1\dots dx^n$. If we then define $dX_n = e^n \wedge \cdots \wedge e^1 dx^1 \dots dx^n$ we then find that
\[
d\Omega = I^\dagger \cdot dX_n.
\]
Here $I$ is the pseudoscalar field defined on $\Omega$ with respect to $g$. Similarly, for $k<n$, we can define the $k$-dimensional volume measure as 
\[
dX_k = \frac{1}{k!}(e^{i_k}\wedge \cdots \wedge e^{i_1}) dx^{i_1} \cdots dx^{i_k}.
\]
We can now write a $k$-form $\alpha_k$ as $\alpha_k = A_k \cdot dX_k$. In this sense, a differential form is made up of two essential components namely the multivector field and the $k$-dimensional volume directed measure. For example, if we wish to write a 2-form $\alpha_2$ we take $dX_2 = \frac{1}{2!} e^j \wedge e^i dx^i dx^j$ and $A_2 = a_{ij} e_i \wedge e_j$ to yield
\[
\alpha_2 = A_2 \cdot dX_2 = \frac{a_{ij}}{2!} (e_i \wedge e_j) \cdot (e^j \wedge e^i) dx^i dx^j = \frac{a_{ij}}{2!} (dx^i dx^j - dx^j dx^i)
\]
Thus, we arrive at an isomorphism between $k$-forms and $k$-vectors as a contraction with the $k$-dimensional volume directed measure $dX_k$ since
\[
\alpha_k = A_k \cdot dX_k.
\]
Hence, we can see now how a differential form simply appends the measure attached to the underlying space. We can also see how this generalizes the musical isomorphisms $\sharp$ and $\flat$ by taking a vector field $a$ and noting
\begin{equation}
\label{eq:line_element}
a \cdot dX_1 = a^i e_i \cdot e^j dx^j = a^i dx^i,
\end{equation}
corresponds to the usual $\flat$ map on vector fields.


\subsubsection{Exterior algebra}
The exterior algebra of differential forms comes with an addition $+$ and exterior multiplication $\wedge$.  We note that the sum of two $k$-forms $\alpha_k$ and $\beta_k$ that $\alpha_k+\beta_k$ is also a $k$-form which we can see by letting $\alpha_k = A_k \cdot dX_k$ and $\beta_k = B_k \cdot dX_k$ and putting
\[
\alpha_k + \beta_k = (A_k \cdot dX_k)+(B_k \cdot dX_k) = (A_k + B_k) \cdot dX_k,
\]
due to the linearity of $\cdot$.  If instead had an $s$ form $\beta_s$ then we have the exterior product
\[
\alpha_k \wedge \beta_s = (A_k \wedge B_k) \cdot dX_{k+s},
\]
where $dX_{k+s}=0$ if $k+s>n$.  


\subsubsection{Exterior derivative}
With differential forms one also has the exterior derivative $d$ giving rise to the calculus of forms.  Given we can write a differential $k$-form as $\alpha_k = A_k \wedge dX_k$,  In particular, we have
\[
d \alpha_k = (\grad \wedge A_k) \cdot dX_{k+1},
\]
which realizes the exterior derivative as the grade raising component of the gradient $\grad$. Of course, for scalar fields, this returns the gradient as desired. 


\subsubsection{Integration on submanifolds}

Given a $k$-dimensional submanifold of $K \subset \Omega$ with a $k$-form $\alpha_k$ defined on $K$, we can integrate the $k$-form. Using the multivector equivalents leads us to the $k$-dimensional directed measure $dK$ for the submanifold $K$.  Given $K$ is a submanifold of $\Omega$, for any $x \in K$ we have tangent space $T_x K$ which corresponds to a tangent $k$-blade $I_K(x)$.  We put $I_K$ as the smooth $k$-blade field everywhere tangent to $K$. Then we have the directed volume measure on $K$ given by
\[
dK = I_K^\dagger \cdot dX_k.
\]
For a tangent $k$-vector field $A_k$ on $K$, we must have for any $x \in K$ that $f = \operatorname{P}_{I_K} \circ f$ so that these fields lie purely tangent to $K$. In particular, we can always put $A_k = A I_k^\dagger$ for a scalar field $A$. These fields can contract with the directed measure $dX_k$ to create a $k$-form on $K$ by $\alpha_k = A_k \cdot dX_k = A dK$ which can be integrated as
\[
\int_K \alpha = \int_K A dK.
\]
Hence, on $\Omega$ itself, we can integrate top forms $\omega = W I^\dagger$ for a scalar field $W$ by
\[
\int_\Omega \omega = \int_\Omega W d\Omega.
\]

There is also the normal space $N_x K$ that is everywhere orthogonal (with respect to $g$ on $\Omega$) to $T_x K$.  In particular, we have the normal $(n-k)$-blade field $\nu = I_K^\dagger I$. Note that for a unit $k$-blade $I_K$ we have $I_K^{-1}=I_K^\dagger$ and we see $I_K \nu = I$. Since $K$ is a submanifold of $\Omega$ we have the inclusion $\iota \colon K \to \Omega$ and the induced pullback on forms $\iota^*$ which is equivalent to the tangent projection operator $\tangent_K$ seen in \cite{schwarz_hodge_1995}. Given a $p$-form $\omega$ defined on $\Omega$, we have that $\tangent_K \omega = \omega \circ \operatorname{P}_{I_K}$. Specifically, $\omega = W \cdot dX_p$ we have 
\[
\iota^* \omega  = W \cdot (dX_p \circ \operatorname{P}_{I_K}) = \operatorname{P}_{I_K}(W) \cdot dX_p.
\]
The normal projection $\normal_K$ is then $\normal_K \omega = \omega - \tangent_K \omega$. 

This is pertinent when we take the submanifold $\Sigma = \partial \Omega$. There, $I_\Sigma$ yields the directed measure
\[
d\Sigma \coloneqq I_\Sigma^\dagger \cdot dX_{n-1}.
\]
The normal space is 1-dimensional and $\nu$ is the unit normal vector to the boundary. The pullback coincides with projection into the tangent space given by $I_\Sigma$.  Then, for 1-forms $\alpha = \cdot dX_1$ it is apparent that $\tangent_\Sigma \alpha = \projection{I_\Sigma}{a} \cdot dX_1$ and $\normal_\Sigma \alpha = \rejection_{I_\Sigma}(a) \cdot dX_1$ by Equations \ref{eq:projection+rejection_vector} and \ref{eq:projection_rejection_vector}. One can then find the flux of a vector field through $\Sigma$ arises as an $(n-1)$-form $\projection{\nu}{a} I^{-1} \cdot dX_{n-1}$. Once again we see that the flux is determined both by the vector field $a$ and the local geometry of $\Sigma$ captured by $d\Sigma$ in the following way. Note that  $\nu^{-1}=\nu$ since $\|\nu\|=1$ everywhere on $\Sigma$ and so $\projection{\nu}{a} I^{-1}= a \cdot \nu \nu I^{-1} = a \cdot \nu I_\Sigma^\dagger$ which gives us the corresponding form $a \cdot \nu d\Sigma$ and the total flux of $a$ through $\Sigma$ is then
\[
\int_\Sigma (\projection{\nu}{a} I^{-1}) \cdot dX_{n-1} = \int_\Sigma a \cdot \nu d\Sigma.
\]

\subsubsection{$k$-form inner product}
\todo[inline]{Show that this relates back to the spinor norm.}
For smooth $k$-forms $\alpha_k = A_k \cdot dX_k$ and $\beta_k = B_k \cdot dX_k$, we have an inner product 
\[
\langle \alpha_k, \beta_k \rangle = \int_\Omega \alpha_k \wedge \star \beta_k 
\]
where $\star$ is the Hodge star. The Hodge star on $k$-forms inputs a $k$-form and outputs a a specific dual $(n-k)$-form so that we always have $\alpha_k \wedge \star \beta_k  = (A_k\cdot B_k^\dagger)d\Omega$ as we note Equation \ref{eq:dot_product}. Thus, we can realize how $\star$ acts on multivector representative. We let $\star \beta_k = B_k^\star \cdot dX_{n-k}$ by $B_k^\star = (I^{-1} B_k)^\dagger$.  Indeed, we have
\begin{align*}
    \alpha_k \wedge \star \beta_k &= (A_k \wedge B_k^\star) \cdot dX_n\\
    &= A_k \cdot B_k^\dagger d\Omega.
\end{align*}

\subsubsection{Stokes' and Green's theorem}

For regions $\Omega$ with boundary $\Sigma$, we have a compact form of Stokes' theorem
\[
\int_\Omega d \omega = \int_\Sigma \tangent \omega,
\]
for sufficiently smooth $(n-1)$-forms $\omega$.

\todo[inline]{More on integration and do Ohms law as an example of some of this stuff. Do all of hodge decomposition and stuff?}