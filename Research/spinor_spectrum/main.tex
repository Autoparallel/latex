\documentclass[12pt]{article}
\usepackage{import}
\usepackage{preamble}
\usepackage{environments}
% package for todo 
\setlength{\marginparwidth}{2cm}
\usepackage[colorinlistoftodos]{todonotes}
\setuptodonotes{size=\scriptsize,backgroundcolor=red!15!white} 

\usepackage{showkeys} %show cites and refs

\title{Determining the homeomorphism type of an embedded manifold from the spinor spectrum}
\author{Colin Roberts}



\begin{document}

 \begin{titlingpage}
     \maketitle
     \vfill
     \begin{abstract}
        \textcolor{red}{TODO}
     \end{abstract}
 \end{titlingpage}


\section{Introduction}

In 1980, Alberto Calder\'on proposed an inverse problem in his paper \emph{On an inverse boundary value problem} \cite{calderon_inverse_2006} where he asks if one can determine the electrical conductivity matrix of some Ohmic medium from knowledge of voltage and current measurements on the boundary of the given domain. This problem goes under the name of Electrical Impedance Tomography (EIT). Physically, the EIT problem is a static 3-dimensional boundary value inverse problem wherein the practicioner has access to voltage to a discrete subset of the boundary of a body and make noisy measurements of the outgoing current flux along the same discrete subset. In other words, a partial and noisy version of the voltage-to-current map is known.

One notes that the voltage-to-current map inputs a scalar potential (the Dirichlet data) on the boundary which, if the conductivity matrix was known, would allow one to determine the potential on the interior by solving a second order elliptic partial differential equation with coefficients defined by the conductivity. In an Ohmic material, the current field is induced by from the electric field (the gradient of the potential) and the conductivity, and hence for a fixed conductivity, utilizing different Dirichlet data can induce different current fields in the body. The practicioner has the ability to measure the outgoing current flux along the boundary (the Neumann data) and thus, they have access to the voltage-to-current map.   

This problem can be generalized naturally into dimensions $\geq 2$ as a geometric inverse problem. One replaces the medium with a manifold and the conductivity becomes the Riemannian metric. Thus, the second order elliptic equation from before amounts to finding scalar fields in the kernel of the Laplace-Beltrami operator. This leads to a small caveat that in dimension 2 since the Laplace-Beltrami operator is conformally invariant. At any rate, the EIT problem is equivalent to determining an unknown Riemannian manifold up to isometry from the classical Dirichlet-to-Neumann (DN) map which inputs a scalar field and outputs the outward normal component of the derivative of the solution \cite{feldman_calderproblem_nodate, salo_calderon_nodate, uhlmann_inverse_2014}. 

There are a handful of approaches to solving this problem, but it remains unsolved. In order to make progress, theorists have allowed themselves access to larger sets of data, for example, complete knowledge of a generalized DN map on differential forms \cite{krupchyk_inverse_2011,sharafutdinov_complete_2013,belishev_dirichlet_2008,joshi_inverse_nodate}. In dimension 2, the smooth problem has been solved up to conformal invariance and in dimension $\geq 3$, the problem has been solved for analytic manifolds \cite{lassas_determining_2001}. Another approach that is unique to a manifold of dimension 2 appears in \cite{belishev_calderon_2003}. In this paper, Belishev determines the algebra of holomorphic functions from the DN map and realizes the spectrum of this algebra homeomorphic to the underlying manifold by Gelfand. The metric $g$ is then recovered up to conformal class by extracting the complex structure from this algebra as well. An attempt to generalize this approach to dimension $n=3$ can be found in by replacing the complex structure with a quaternionic structure but this has not lead to a complete solution \cite{belishev_algebras_2017, belishev_algebraic_2019}. It has been shown that the 3-dimensional round ball can be determined up to homeomorphism from a quaternionic spectrum. Belishev and Vakulenko ask whether this can be extended to higher dimensions and to other spaces. An answer to this question is provided by \cref{thm:gelfand}.

In this work, I first introduce the geometric algebras $\G$ as special cases of more general Clifford algebras in \cref{subsec:clifford_and_geometric_algebras}. Following this, I take a smooth, oriented, Riemannian manifold $M$ and construct a Clifford algebra bundle whose sections lie in the space $\G(M)$ and are referred to as multivector fields in \cref{sec:geometric_manifolds}. The graded algebraic structure of $\G(M)$ expands upon the exterior algebra of forms $\Omega(M)$, and moreover, there exists a natural differential structure via the gradient operator $\grad$, which finds similarities to the Hodge-Dirac operator $d+\delta$. The space $\G(M)$ proves to be more rich than $\Omega(M)$ since one can realize $\Omega(M)$ as a trivial case of some $\G(M)$. Moreover, it is quite natural to look at multivector fields that consist of many differently graded elements at once. For example, multivector fields that lie in the kernel of $\grad$ are called monogenic and these fields share many of the same properties as holomorphic functions on $\C$ including, but not limited to, a Cauchy integral formula \cref{eq:cauchy_integral}. However, unlike holomorphic functions, the space of monogenic fields $\monogenicfields{}$ is not, in general, commutative or an algebra.

A useful version of a Green's formula is shown in \cref{thm:multivector_greens_formula}, and this allows us to prove a multivector version of the Hodge-Morrey decomposition that we realize in the following theorem.
\begin{customthm}{3.1.1}[Monogenic Hodge Decomposition]
The space of multivector fields $\G(M)$ has the $L^2$-orthogonal decomposition
\begin{equation}
\G(M) = \monogenicfields{} \oplus \pseudoscalar^{-1} \grad \G(M).
\end{equation}
\end{customthm}

The space $\monogenicfields{}$ is a right module over the constant multivectors $\G$. For the special case of the Euclidean geometric algebra $\G_n$, I define a space of module homomorphisms from $\monogenicfields{}$ to $\G_n$ and refer to these morphisms $\G_n$-functionals. Inside $\monogenicfields{}$ lie commutative subalgebras $\algebra{\bivector}(M)$ that are analogs of $\C$ and on these algebras we can define $\G_n$-characters as the $\G_n$-functionals that are also algebra morphisms on each $\algebra{\bivector}(M)$ into $\G_n$. The space of $\G_n$-characters, $\characters(M)$, with the weak-$\ast$ topology, is shown to be homeomorphic to $M$ in the special case where $M$ is a region of $\R^n$ and inherits the Euclidean metric. This is summarized in the following theorem.
\begin{customthm}{3.3.1}
For any $\delta \in \characters(M)$, there is a point $x^\delta \in M$ such that $\delta(f) = f(x^\delta)$ for any $f\in \monogenics(M)$ a monogenic field. Given the weak-$\ast$ topology on $\dualmonogenics(M)$, the map
\[
\gamma \colon \characters(M) \to M, \quad \delta \mapsto x^\delta
\]
is a homeomorphism. 
%The Gelfand transform 
%\[
%\widehat{~} \colon \monogenics(M) \to C(\characters(M); \G_n), \quad \widehat{f}(\delta) \coloneqq \delta(f), \quad \delta \in \characters(M),
%\]
%is an isometry onto its image, so that $\characters(M)$ is isomorphic to $\widehat{\monogenics(M)}$ as algebras.
\end{customthm}

Owing to the original intention of this work, I consider physical and geometric inverse boundary value problems related to the Calder\'on problem. For example, I discuss the electric and magnetic impedance tomography problems and their statements in terms of multivector fields \cref{sec:tomography}. Relationships between the two problems are established, and one finds that the Ohmic property of a medium couples together the scalar potential $u$ and the magnetic bivector field $b$ into a single monogenic field. Given knowledge of the electrostatic and magnetostatic version of the DN map alongside this new relationship, can one determine the underlying conductivity? Likewise, in higher dimensions, do \cref{thm:gelfand,thm:monogenic_hodge} provide new tools for solving the Calder\'on or other related inverse problems? Finally, there also exists a Hilbert transform in two guises via \cite{belishev_dirichlet_2008,brackx_hilbert_2008}. Are these two notions equivalent? Does either add any more useful information for solving boundary inverse problems?

\section{Preliminaries}


The complex algebra $\C$ can be generalized in a handful of ways.  Some of which can be found through the use of Clifford algebras and, more specifically, in geometric algebras.  We define the more general Clifford algebras first and realize geometric algebras as particularly nice Clifford algebras with a quadratic form arising from an inner product. Elements of a geometric algebra are known as multivectors and these multivectors carry a wealth of geometric information in their algebraic structure. $\C$ itself can be realized as a special subalgebra of parabivectors in the geometric algebra on $\R^2$ with the Euclidean inner product and the quaternions $\quat$ are realized as an analogous algebra on $\R^3$. In particular, both $\C$ and $\quat$ arise as the 2- and 3-dimensional even Clifford groups $\Gamma^+$ respectively. \todo{reword this paragraph}

First, we present a review of Clifford algebras and the relevant notions needed for this work. Those who feel they are familiar with both Clifford and geometric algebras may wish to skim through this subsection and visit \cref{subsubsec:motivating_example} to review the notation used throughout this manuscript. 

Formally, we let $(V,Q)$ be an $n$-dimensional vector space $V$ over some field $K$ with an arbitrary quadratic form $Q$.  The tensor algebra is given by
\begin{equation}
\mathcal{T}(V) \coloneqq \bigoplus_{j=0}^\infty V^{\otimes j} = K \oplus V \oplus (V\otimes V) \oplus (V\otimes V \otimes V) \oplus \cdots,
\end{equation}
where the elements (tensors) inherit a multiplication $\otimes$ (the tensor product). From the tensor algebra $\mathcal{T}(V)$, we can quotient by the ideal generated by $\blade{v}\otimes \blade{v} - Q(\blade{v})$ to create a new algebra.
\begin{definition}
The \emph{Clifford algebra} $C\ell(V,Q)$ is the quotient algebra
\begin{equation}
C\ell(V,Q) = \mathcal{T}(V) ~ / ~ \langle \blade{v} \otimes \blade{v} - Q(\blade{v}) \rangle.
\end{equation}
\end{definition}
To see how the tensor product descends to the quotient, we let $\blade{v}_1, \dots, \blade{v}_n$ be an arbitrary basis for $V$, then we can consider the tensor product of basis elements $\blade{v}_i \otimes \blade{v}_j$ which induces a product in the quotient $C\ell(V,Q)$ which we refer to as the \emph{Clifford multiplication}. In this basis, we write this product as concatenation $\blade{v_i}\blade{v_j}$ and define the multiplication by
\begin{equation}
\label{eq:clifford_multiplication}
\blade{v}_i \blade{v}_j = \begin{cases} Q(\blade{v}_i) & \textrm{if $i=j$}, \\ \blade{v}_i \wedge \blade{v}_j & \textrm{if $i\neq j$},\end{cases}
\end{equation}
where $\wedge$ is the typical exterior product satisfying $\blade{v}\wedge \blade{w} = - \blade{w}\wedge \blade{v}$ for all $\blade{v},\blade{w}\in V$.  As a consequence, the exterior algebra $\bigwedge(V)$ can be realized as a subalgebra of any Clifford algebra over $V$ or as a Clifford algebra with a trivial quadratic form $Q=0$.  

In the case where $V$ has a (pseudo) inner product $g$, we can induce a quadratic form $Q$ by $Q(\blade{v})=g(\blade{v},\blade{v})$ and give rise to a special type of Clifford algebra which motivates the following definition.
\begin{definition}
Let $V$ be a vector space with an (pseudo) inner product $g(\cdot,\cdot)$. Then taking $Q(\cdot) = g(\cdot,\cdot)$, the Clifford algebra $C \ell(V,Q)$ is called a \emph{geometric algebra}.
\end{definition}
In general, we put $\G$ and assume the inner product and vector space will be arbitrary, given alongside, or will be clear from context.  For example, when $V=\R^n$ we have the standard orthonormal basis $\blade{e}_1,\dots,\blade{e}_n$ which allows us to neatly define the quadratic form $Q$ from the Euclidean inner product which has coefficients $\delta_{ij}$ with respect to this basis. Since we frequently utilize this geometric algebra, we put $\mathcal{G}_n \coloneqq C\ell(\R^n, |\cdot|)$ to simplify notation.  In broader generality, we do not need to have a definite inner product. For example, we can take an inner product where $p$ vectors square to negative values and $q$ vectors square to positive values which is of interest for those studying curved spacetime. Vectors whose square is negative are \emph{temporal} and those whose square is positive are \emph{spatial}. We put $\G_{p,q}$ for a geometric algebra with $p$ temporal vectors and $q$ spatial vectors where, in particular, $p$ vectors square to $-1$ and $q$ vectors square to 1.. The factor $p$ will return in various different calculations.

Geometric algebras are an old and widely studied topic. For more information, see the classical text \cite{hestenes_clifford_1986} or the more modern text \cite{doran_geometric_2003} which also provides a wide range of applications to physics problems. Both these sources include much of the other necessary preliminaries I cover in the remainder of this section. Finally, the paper \cite{chisolm_geometric_2012} proves many of the useful identities and notation used throughout this paper.

\subsection{Multivectors and grading}
\todo{fix all vector indices to be not bold}
Note that $C\ell(V,Q)$ is a $\mathbb{Z}$-graded algebra with elements of grade-0 up to elements of grade-$n$. We refer to grade-0 elements as scalars, grade-1 elements as vectors, grade-2 elements as \emph{bivectors}, grade-$r$ elements as \emph{$r$-vectors}, and grade-$n$ elements as \emph{pseudoscalars}. For example, the pseudoscalar $\blade{\mu} = \blade{v}_1 \wedge \blade{v}_2 \wedge \cdots \wedge \blade{v}_n$ is an $n$-vector we will frequently return to. We denote the space of $r$-vectors by $C\ell(V,Q)^r$. For each grade there is a basis of ${n\choose r}$ \emph{$r$-blades} which are $r$-vectors of the form
\begin{equation}
\label{eq:blade}
\blade{A_r} = \bigwedge_{j=1}^r \blade{v}_j, ~\textrm{for linearly independent}~ \blade{v}_j \in V,
\end{equation}
and we use a boldface of both the character and its subscript to specify that a $r$-vector is a $r$-blade and we note that vectors (since they are $1$-blades) will not use this subscript. Instead, a vector $\blade{v}$ may use a non-boldfaced subscript to reference an index. Briefly, take for example the case where $\dim(V)=3$, then there are ${3\choose 2}=3$ 2-blades that form a basis for the bivectors and one particular choice of a bivector basis would be the following list of 2-blades
\begin{equation}
\label{eq:3_dim_basis}
\blade{B}_{12} = \blade{v}_1 \wedge \blade{v}_2, \quad \blade{B}_{13} = \blade{v}_1 \wedge \blade{v}_3, \quad \blade{B}_{23} = \blade{v}_2 \wedge \blade{v}_3.
\end{equation}
We will repeatedly use the notation $\blade{B}_{ij} \coloneqq \blade{v}_i\wedge \blade{v}_j$ and the underlying basis will be clear from context. We refer to an $n-1$-vector as a \emph{pseudovector} and it should be noted that every $n-1$-vector is a blade (see \cref{subsubsec:duality_and_pseudoscalars}). In other literature, some will refer to a $r$-blade as a \emph{simple} or a \emph{decomposable} $r$-vector\todo{citations}. 

In general, an element $A \in C\ell(V,Q)$ is written as a linear combination of basis elements of all possible grades and we refer to $A$ as a \emph{multivector}.  To extract the grade-$r$ components of $A$, we use the \emph{grade projection} for which we have the notation
\begin{equation}
\proj{r}{A} \in C\ell(V,Q)^r
\end{equation}
to denote the grade-$r$ components of the multivector $A$ (i.e., $\proj{r}{A} \in C\ell(V,Q)^r$). For the scalar component we put $\proj{}{A}$ and we can note we have the cyclic property
\begin{equation}
\label{eq:cyclic_property}
\proj{}{AB\cdots CD} = \proj{}{DAB\cdots C}
\end{equation} 
Any multivector $A$ can then be given by
\begin{equation}
A = \sum_{r=0}^n \proj{r}{A}
\end{equation}
which shows the decomposition via the $\mathbb{Z}$-grading
\begin{equation}
C\ell(V,Q) = \bigoplus_{j=0}^n C\ell(V,Q)^j.
\end{equation}
If $A$ contains only components of a single grade, then we say that $A$ is \emph{homogeneous} and if the components are grade-$r$ we put $A_r$ and refer to $A_r$ as a \emph{homogeneous $r$-vector} or simply an \emph{$r$-vector}.  For example, when we refer to vectors we realize them as 1-vectors and likewise we realize bivectors as 2-vectors. Also of interest will be the elements in
\begin{equation}
 C\ell(V,Q)^{0+2} = C\ell(V,Q)\oplus C\ell(V,Q)^2
\end{equation}
which we refer to as \emph{surface spinors}. \todo{Maybe just define these later with the spinors and call these surface spinors}

The Clifford multiplication of vectors defined in \ref{eq:clifford_multiplication} can be extended to multiplication of vectors with homogeneous $r$-vectors.  In particular, given a vector $\blade{v} \in C\ell(V,Q)$ and a homogeneous $r$-vector $A_r \in C\ell(V,Q)$, we have
\begin{equation}
\label{eq:vector_multiplication}
\blade{v}A_r = \proj{r-1}{\blade{v}A_r} + \proj{r+1}{\blade{v}A_r},
\end{equation}
which decomposes the multiplication into a grade lowering \emph{interior product} and a grade raising \emph{exterior product}.  This allows us to extend the Clifford multiplication further. Given an $s$-vector $B_s$, we have
\begin{equation}
\label{eq:general_clifford_multiplication}
A_r B_s = \proj{|r-s|}{A_rB_s} + \proj{|r-s|+2}{A_rB_s} + \cdots + \proj{r+s}{A_rB_s}.
\end{equation}
This rule for multiplication then allows for the multiplication of two general multivectors in $C\ell(V,Q)$. For this multiplication, specific grades of the product are worth noting.
\begin{equation}
\label{eq:dot}
    A_r \cdot B_s \coloneqq \proj{|r-s|}{A_r B_s}
\end{equation}
\begin{equation}
\label{eq:wedge}
    A_r \wedge B_s \coloneqq \proj{r+s}{A_r B_s}
\end{equation}
\begin{equation}
\label{eq:left_contraction}
    A_r \rfloor B_s \coloneqq \proj{s-r}{A_r B_s}
\end{equation}
\begin{equation}
\label{eq:right_contraction}
    A_r \lfloor B_s \coloneqq \proj{r-s}{A_r B_s}.
\end{equation}
Finally, we have a special product for bivectors called the \emph{commutator product} given by
\begin{equation}
\label{eq:commutator_product}
    A_2 \times B_2 \coloneqq \proj{2}{A_2 B_2} \equiv \frac{1}{2} (A_2 B_2 - B_2 A_2).
\end{equation}
These products are particularly emphasized as many helpful identities used in this paper are phrased using these notions. For example,
\begin{equation}
\label{eq:contraction_swap}
A_r \rfloor B_s = (-1)^{r(s-1)}B_s \lfloor A_r
\end{equation}
\begin{equation}
\label{eq:wedge_swap}
A_r \wedge B_s = (-1)^{rs}B_s\wedge A_r.
\end{equation}
Proofs for the identities used throughout can be found in \cite{chisolm_geometric_2012}.  Taking \cref{eq:vector_multiplication,eq:wedge,eq:left_contraction} into mind, we see that the grade lowering interior product can be written as
\begin{equation}
    \proj{r-1}{\blade{v}A_r} \equiv \blade{v}\rfloor A_r \equiv \blade{v} \cdot A_r
\end{equation}
and the grade raising exterior product can be written as
\begin{equation}
    \proj{r+1}{\blade{v}A_r} \equiv \blade{v} \wedge A_r.
\end{equation}
Finally, to suppress needless additional parentheses later on, we assert that the above products take precedence over the geometrical product in order of operation. For example, for multivectors $A$, $B$, and $C$, we must take
\begin{equation}
A\cdot B C \equiv (A \cdot B)C,
\end{equation}
and extend this to the other products defined in \cref{eq:wedge,eq:left_contraction,eq:right_contraction,eq:commutator_product} as well.

We can also define an inner product on multivector fields that captures that mimics Euclidean inner product on structure of $\R^{2^n}$, i.e., treating each of the basis blades as independent vectors in $\R^{2^n}$. 
\begin{definition}
Let $A,B \in \G$, then the \emph{multivector inner product} is given by
\begin{equation}
(A,B) \coloneqq \proj{}{A^\dagger B}.
\end{equation}
\end{definition}
This product is bilinear, symmetric, positive definite, and satisfies
\begin{equation}
(A,B)=(A^\dagger,B^\dagger)
\end{equation}
so long as $g$ is positive definite. The product $(\cdot,\cdot)$ is a natural extension of the inner product $g$ on the $n$-dimensional space $V$ to the $2^n$-dimensional $\G$. To see this, take an orthonormal basis $\blade{e}_1,\dots,\blade{e}n$ and construct the basis of blades by defining an index set $J=\{j_1,j_2,\dots,j_r\}$ for $0<j_1<j_2<\cdots< j_r\leq n$. The set of all such $J$ for all $0\leq r \leq n$ allows us to define the basis blades $\blade{E}_J = \blade{e}_{j_1}\cdots \blade{e}_{j_r}$ for which we can define any multivector $A$ by $A = \sum_J A_J \blade{E}_J$ where $A_J$ are scalar coefficients. The inner product then returns
\begin{equation}
(A,B) = \sum_{J} A_JB_J.
\end{equation}
The symmetry, definiteness, and bilinearity become apparent. However, if $g$ is not positive definite, then there are vectors called \emph{null vectors} such that $(\blade{v},\blade{v})=0$. This can be realized in the spacetime algebra (see \cref{subsec:motivating_example}).

With this inner product, we have a notion of an adjoint.
\begin{proposition}
\label{prop:adjoint}
Take $A,B,C \in \G$ then
\begin{align}
(CA,B) &= (A,C^\dagger B)\\
(AC,B) &= (A,BC^\dagger)
\end{align}
\end{proposition}
\begin{proof}
First,
\begin{align}
(CA,B) = \proj{}{(CA)^\dagger B} = \proj{}{ A^\dagger C^\dagger B } = (A,C^\dagger B),
\end{align}
and
\begin{align}
(AC,B) = \proj{}{(AC)^\dagger B} = \proj{}{ C^\dagger A^\dagger B } = (A,BC^\dagger),
\end{align}
both by \cref{eq:cyclic_property}
\end{proof}
Also, we have the induced norm.
\begin{definition}
    The \emph{multivector norm} $| \cdot |$ for $A \in \G$ is given by
    \begin{equation}
    |A| \coloneqq \sqrt{(A,A)}.
    \end{equation}
\end{definition}

As discussed, $C\ell(V,Q)$ is naturally a $\mathbb{Z}$-graded algebra but we also find that it carries a $\mathbb{Z}/2\mathbb{Z}$-grading as well. Some would then refer to $C\ell(V,Q)$ as an \emph{superalgebra} \todo{source}. This additional grading can be realized by sorting $r$-vectors in $C\ell(V,Q)$ into the sets where $r$ is even or odd.  We say a $r$-vector is \emph{even} (resp. \emph{odd}) if $r$ is even (resp. odd) and in general if a multivector $A$ is a sum of only even (resp. odd) grade elements we also refer to $A$ as even (resp. odd).  Taking note of the multiplication defined in \ref{eq:general_clifford_multiplication}, one can see that the multiplication of even multivectors with another even multivectors outputs an even multivector and that motivates the following.
\begin{definition}
The \emph{even subalgebra} $C\ell(V,Q)^+ \subset C\ell(V,Q)$ is the subalgebra of even grade multivectors
\begin{equation}
    C\ell(V,Q)^+ \coloneqq C\ell(V,Q)^0 \oplus C\ell(V,Q)^2 \oplus C\ell(V,Q)^4 \oplus \cdots.
\end{equation}
\end{definition}
The split between even and odd subspaces of $C\ell(V,Q)$ makes the space $C\ell(V,Q)$ into a \emph{superalgebra}. Though, one should note that the space of odd grade multivectors, $C\ell(V,Q)^-$, is not an algebra in its own right, it is a $C\ell(V,Q)^+$-module. We can then take the even part of a multivector $A$ by $\proj{+}{A}$ and the odd part by $\proj{-}{A}$ and note
\begin{equation}
A = \proj{+}{A} + \proj{-}{A}.
\end{equation}
In the same vein, we will denote an even multivector by $A_+$ and an odd multivector by $A_-$. The even subalgebra is an extremely important entity that arises throughout physics due to its encapsulation of spinors which we touch on next. 

\subsection{Multivector operations and the Clifford and spin groups}
\label{subsubsec:reverse_inverse_clifford_spin_groups}
For the remainder of this paper, let us focus solely on geometric algebras $\G$. Given access to an (pseudo) inner product we have a natural isomorphism between $V$ and $V^*$ by the Riesz representation.  Namely, given an arbitrary basis $\blade{v}_i$ for $V$ there exists the corresponding dual basis $f_i$ for $V^*$ such that $f_i(\blade{v}_j)=\delta_{ij}$. In geometric algebra, this notion is somewhat superfluous as we can realize the dual basis inside $V$ itself in the following manner. Note that there is a unique map $\sharp \colon V^* \to V$ for which $f\mapsto \blade{f^\sharp}$ such that
\begin{equation}
\blade{f_i^\sharp} \cdot \blade{v}_j = \delta_{ij}.
\end{equation}
Hence, if we simply put $\blade{v}^i \coloneqq \blade{f^\sharp}_i$ we can note that $\blade{v}^i$ is simply a vector in the geometric algebra.
\begin{definition}
Let $\blade{v}_1,\blade{v}_2,\dots,\blade{v}_n$ be an arbitrary basis of $V$ generating $\G$. Then we have the \emph{reciprocal basis} $\blade{v}^1,\blade{v}^2,\dots,\blade{v}^n$ satisfying
\begin{equation}
    \blade{v}^i\cdot \blade{v}_j = \delta^i_j,
\end{equation}
and we refer to each $\blade{v}^i$ as a \emph{reciprocal vector}.
\end{definition}
In terms of the inner product $g$, we have that the coefficients are given by $g_{ij}=\blade{v}_i\cdot \blade{v}_j$ and thus we have an explicit definition for the reciprocal vectors by putting $\blade{v}^i = g^{ij}\blade{v}_j$ where $g^{ij}$ is the coefficients to the matrix inverse $(g_{ij})^{-1}$ and we assume the Einstein summation convention. 

The inverse to this isomorphism is $\flat \colon V \to V^*$ which is given by $\blade{v} \mapsto v^\flat$ satisfying
\begin{equation}
v_i^\flat (\blade{v}_j)= \delta_{ij}.
\end{equation}
Given these identifications, there is no need to distinguish between the vector space $V$ and its dual $V^*$ as it suffices to consider $V$ itself with reciprocal vectors $\blade{v^i}$ with the application of the scalar product. For reference, the maps $\sharp$ and $\flat$ are the \emph{musical isomorphisms} \todo{sources}.

For a geometric algebra with a positive definite inner product, all blades have an inverse and hence form a group. With a pseudo inner product, the invertible elements are not quite as broad\todo{give an example later}. To this end, we can construct a group of all invertible elements referred to as the \emph{Clifford group} $\Gamma(\G)$ for an arbitrary geometric algebra $\G$ by
\begin{equation}
\Gamma(\G) \coloneqq \left\{ \prod_{j=1}^k \blade{v}_j ~\vert~ k\in \mathbb{Z}^+,~ \forall j~\colon1\leq j \leq k~\colon~\blade{v}_i \in V ~\textrm{such that}~ g(\blade{v}_i,\blade{v}_i)\neq 0\right\}.
\end{equation}
We refer to elements of the Clifford group as \emph{Clifford multivectors}. Note that Clifford multivectors are not necessarily blades since the product used in the construction is not the exterior product $\wedge$. For any Clifford multivectors $A = \blade{v}_1 \cdots \blade{v}_k$ in the group $\Gamma$, we have that multiplicative inverse $A^{-1}$ is given by $A^{-1} = \blade{v}^k \dots \blade{v}^1$ as we can see that $A^{-1}A=AA^{-1} = 1$ by construction.  Another note is that all scalars, vectors, pseudovectors, and pseudoscalars are always in the Clifford group and have multiplicative inverses. The inverse of a vector $\blade{v}$ is given by $\frac{\blade{v}}{\blade{v}\cdot\blade{v}}$. The form of the inverse motivates the utility of the \emph{reverse} operator $\dagger$ defined so that $A^\dagger = \blade{v}_k \cdots \blade{v}_1$. For a $r$-blade $A_r$, the reverse also satisfies the relationship
\begin{equation}
\label{eq:reverse_sign}
A_r^\dagger = (-1)^{r(r-1)/2} A_r
\end{equation}
as well as
\begin{equation}
\label{eq:dagger_distribution}
(AB)^\dagger = B^\dagger A^\dagger.
\end{equation}
One can see that the multiplicative inverse of an element of the Clifford group $A$ is the reverse of the corresponding product of reciprocal vectors since $A_r^{-1} = (\blade{v}^1 \cdots \blade{v}^k)^\dagger$. When we take $V=\R^n$ with the Euclidean inner product, we can note that elements $s \in \Gamma^+(\G_n)$ act as rotations on multivectors $A\in \G_n$ through a conjugate action
\begin{equation}
A \mapsto s A s^{-1}.
\end{equation}
In fact, all nonzero vectors $\blade{v}\in\Gamma(\G_n)$ define a reflection in the hyperplane perpendicular to $\blade{v}$ via the same conjugation action above. This allows one can realize that all rotations are even products of reflections.

Following these realizations, one can see that the Clifford group $\Gamma(\G)$ contains important subgroups such as the orthogonal and special orthogonal groups as quotients \todo{Change these to $O(V)$ and stuff for example}
\begin{equation}
\operatorname{O}(V) \cong \Gamma(\G)/(\R\setminus 0) \qquad \textrm{and} \qquad \operatorname{SO}(V) \cong \Gamma^+(\G) /(\R\setminus 0),
\end{equation}
where $\R\setminus 0$ is the multiplicative group of real numbers. We give the name \emph{unit} to $r$-blades $\blade{A_r}$ with unit Clifford norm $1=|\blade{A_r}|$. Finally, this allows us to arrive at a definition for the classical pin and spin groups.
\begin{definition}
\begin{subequations}
The \emph{pin} and \emph{spin} groups $\operatorname{Pin}(V)$ and $\operatorname{Spin}(V)$ are defined to be
\begin{align}
    \operatorname{Pin}(V) &\coloneqq \{s\in \Gamma(\G) ~\vert~ |s|=1\}.\\
    \operatorname{Spin}(V) &\coloneqq \{s\in \Gamma^+(\G) ~\vert~ |s|=1\}.
\end{align}
\end{subequations}
\end{definition}

Our focus will be the case where we take $\G=\G_n$ for which we put $\spingroup$, but these statements can often be more broadly generalized. Moreover, we can realize this group as a quotient of the Clifford group $\Gamma(\G_n)$ by
\begin{equation}
\operatorname{Spin}(V) \cong \Gamma^+(\G)/\R_+,
\end{equation}
where $\R_+$ is the multiplicative group of positive real numbers. The spin group $\operatorname{Spin}(V)$ is a Lie group usually derived via a short exact sequence of groups
\begin{equation}
1 \to \mathbb{Z}/2\mathbb{Z} \to \operatorname{Spin}(V) \to \operatorname{SO}(V) \to 1.
\end{equation}
Here, we have given a more concrete realization of the spin group as special elements inside a geometric algebra. The Lie algebra of the spin group is denoted by $\mathfrak{spin}(V)$ and $\mathfrak{spin}(n)$ when referencing $\spingroup$. This algebra typically characterized as the tangent space of $\operatorname{Spin}(V)$ at the identity. However, through this approach, we realize that $\mathfrak{spin}(V)$ is isomorphic to the algebra of bivectors with the antisymmetric product $\times$\todo{provide a citation.}.  Then, for any bivector $B$, we can generate an element in the spin group given via the exponential
\begin{equation}
e^{B} = \sum_{j=0}^\infty \frac{B^n}{n!}.
\end{equation}
Fundamentally, the even subalgebra $\G^+$ is invariant under the action of $\operatorname{Spin}(V)$ since all elements in both sets are of even grade. This definition follows.
\begin{definition}
Let $\G$ be a geometric algebra with an inner product of arbitrary signature, then we define a \emph{spinor} to be an element of $\G^+$.
\end{definition}
Morally, this definition is telling us $\psi \in \G^+$ is an element that transforms under a left action of an element of $\operatorname{Spin}(V)$ to produce another spinor which leaves us with a convenient definition in that a spinor is simply an even multivector. Or, in other words, we realize that $\G^+$ is really a left $\operatorname{Spin}(V)$ module. Likewise, it motivates the name of surface spinor for the multivectors consisting of only grade-0 and grade-2 elements. For more on the topic, see \cite{janssens_special_nodate}.

\todo{spinors are really a module. The odd subspace is also a similar module. Maybe reference superalgebra and physics again a little bit.}

\subsection{Pseudoscalars and duality}
\label{subsubsec:duality_and_pseudoscalars}

Pseudoscalars are a deeply useful aspect of geometric algebra and we will now cover some of their utility. First and foremost, these pseudoscalars grant us a means of determining volumes. This will be a necessary notion in order to define integration in \cref{subsec:integration_on_submanifolds}.
\begin{definition}
Let $\G$ be a geometric algebra, then the \emph{volume element} in the arbitrary basis $\blade{v}_1,\dots,\blade{v}_n$ is 
\begin{equation}
\blade{\mu}=\blade{v}_1 \wedge \blade{v}_2 \wedge \cdots \wedge \blade{v}_n.
\end{equation}
\end{definition}
It is worth noting that all volume elements and pseudoscalars are invertible in any geometric algebra. 

We also want to note that the volume element here fits our intuition and indeed we find
\begin{equation}
\label{eq:pseudoscalar_norm}
|\blade{\mu}| = \sqrt{\det(g)}.
\end{equation}
Since pseudoscalars are generated by a single element (recall there are ${n \choose n}$ independent grade-$n$ elements), we should realize that the volume element is simply a scalar copy of a pseudoscalar that is unital.
\begin{definition}
Let $\blade{\mu}$ be the volume element, then we have the \emph{unit pseudoscalar}
\begin{equation}
\blade{I} \coloneqq \frac{1}{|\blade{\mu}|} \blade{\mu}.
\end{equation}
\end{definition}
As is clear by the definition above, we must have that
\begin{equation}
|\blade{I}| = 1.
\end{equation}
The unit pseudoscalar satisfies a useful relationship when swapping the left for right multiplication with an $r$-vector by
\begin{equation}
\blade{I} A_r = (-1)^{r(n-1)} A_r \blade{I}.
\end{equation}
Thus, $\blade{I}$ always commutes with the even subalgebra and the commutation property with the odd subalgebra depends on the dimension. Then, we can note
\begin{equation}
\blade{I}^2 = (-1)^{n(n-1)/2+p},
\end{equation}
which lets us see that the inverse is given by
\begin{equation}
\blade{I}^{-1} = (-1)^{n(n-1)/2+p} \blade{I},
\end{equation}
which is an identification that we will often use. Formulas throughout are usually given in their most general context and substitution is done only when working with specialized algebras. From here, one notices that when $g$ is positive definite we have no temporal vectors and $p=0$ which means $\blade{I}^\dagger = \blade{I}^{-1}$.

Note that for a homogeneous $r$-rector $A_r$ we have that $A_r^\perp$ is an $n-r$-vector. Indeed, if we take an invertible $r$-blade $\blade{A_r}$, then we can find the \emph{$\blade{A_r}$-subspace dual} of a multivector $B$ by
\[
B \rfloor \blade{A_r}^{-1}.
\]
The notions of duality here give us geometrical insight. Taking an $s$-blade $\blade{B_s}$ we can note:
\begin{itemize}
    \item If $s>r$, the $\blade{A_r}$-subspace dual of $\blade{B_s}$ vanishes.
    \item If $s=r$, the $\blade{A_r}$-subspace dual of $\blade{B_s}$ is a scalar and is zero if $\blade{B_s}$ contains a vector orthogonal to $\blade{A_r}$.
    \item If $s<r$, the $\blade{A_r}$-subspace dual of $\blade{B_s}$ represents the orthogonal complement of the subspace corresponding to $\blade{B_s}$ in the subspace corresponding to $\blade{A_r}$.
\end{itemize}  
Since the pseudoscalar is a blade representing the entire vector space, this allows one to create dual elements within the entire vector space. 
\begin{definition}
Given a multivector $B$, we define the \emph{dual} of $B$ to be
\begin{equation}
B^\perp \coloneqq B \rfloor \blade{I}^{-1} \equiv B\blade{I}^{-1}.
\end{equation}
\end{definition}
The dual allows one to exchange interior and exterior products in the following way.
\begin{equation}
\label{eq:wedge_to_dot}
 (A \wedge B)^\perp  = A\rfloor B^\perp
\end{equation}
\begin{equation}
\label{eq:dot_to_wedge}
    (A\rfloor B)^\perp = A \wedge B^\perp
\end{equation}
This shows the natural duality between the inner and exterior products and their interpretations as subspace operations. The duality extends further to provide an isomorphism between the spaces of $r$-vectors and $n-r$-vectors since for any $r$-vector $A_r$ we have $A_r^\perp$ is an $n-r$-vector. It is under this isomorphism one can realize that all pseudovectors are $n-1$-blades. Furthermore, for multivectors $A$ and $B$,
\begin{equation}
(AB)^\perp = AB^\perp
\end{equation}
For those familiar with the Hodge star operator, $\star$, this should feel familiar. This is discussed in \cref{subsec:differential_forms}.

\begin{remark}
\label{rem:cross_product}
If we consider $\spacealg$, we can realize the cross product of two vectors $\blade{u}$ and $\blade{v}$ by
\begin{equation}
\label{eq:cross_product}
\blade{u} \cross \blade{v} \coloneqq (\blade{u}\wedge \blade{v})^\perp \equiv \blade{u} \rfloor \blade{v}^\perp
\equiv (\blade{u}^\perp)\times (\blade{v}^\perp) , 
\end{equation}
where we use the bold notation for $\cross$ to distinguish between the bivector commutator product $\times$ defined in \cref{eq:commutator_product}. The special fact of $\spacealg$ that is abused in a standard multivariate calculus course is that vectors and bivectors are dual to one another. In fact, the first equality is exactly this pedagogical reasoning; the cross product returns a vector perpendicular to the subspace spanned by the two input vectors and is zero when the two inputs are linearly dependent. One can also note that the vector $\blade{w}=\blade{u}\cross \blade{v}$ is sometimes refered to as axial and in other cases the pseudovector $\blade{u}\wedge \blade{v}$ is referred to as axial. The similar product notation of $\times$ and $\cross$ now becomes transparent. 
\end{remark}


\subsection{Blades and subspaces}
\label{subsubsec:blades_and_subspaces}

Each invertible unit $r$-blade $\blade{U_r}$ ($|\blade{U_r}|=1$) corresponds to a $r$-dimensional subspace and can be identified with a point in the Grassmannian of $r$-dimensional subspaces in an $n$-dimensional vector space, $\Grassmannian{r}{n}$. We will often allude to this identification directly by referring to a subspace via a reference to a unit blade, e.g., the subspace $\blade{U_r}$. Extending the dual to act on the unit $r$-blades that make up $\Grassmannian{r}{n}$, one realizes that $\Grassmannian{r}{n}^\perp = \Grassmannian{n-r}{n}$ shows the spaces are in bijection. Moreover, given a subspace $\blade{U_r}$, we can complete the vector space by
\begin{equation}
\blade{U_r}\wedge \blade{U_r}^\perp = \blade{I}.
\end{equation} 
We can also note that any invertible blade $\blade{A_r}$ is simply a scaling of some unit blade so that $\blade{A_r} = \alpha \blade{U_r}$. This interpretation also proves to be a wonderfully geometrical perspective on the products defined in \cref{eq:dot,eq:wedge,eq:left_contraction,eq:right_contraction}. For example, we see that there are a handful of reasons to adopt the additional multiplication symbols $\rfloor$ and $\lfloor$. 
\begin{itemize}
    \item The products $\rfloor$ and $\lfloor$ allow us to avoid needing to pay special attention to the specific grade of each multivector in a product. The product $\cdot$ on $A_r$ and $B_s$ depends on $k$ and $s$ and as such given by either $\rfloor$ or $\lfloor$ but one must know $k$ and $s$ in order to define this product exactly. 
    \item We gain geometrical insight on the structure of $r$-blades in terms of their corresponding subspaces. Let $\blade{A_r}$ and $\blade{B_s}$ be nonzero blades with $r,s\geq 1$ then
    \begin{itemize}
        \item $\blade{A_r} \rfloor \blade{B_s} =0$ iff $\blade{A_r}$ contains a nonzero vector orthogonal to $\blade{B_s}$.
        \item If $r<s$ then if $\blade{A_r}\rfloor \blade{B_s} \neq 0$ then the result is a $s-r$-blade representing the orthogonal complement of $\blade{A_r}$ in $\blade{B_s}$.
        \item If $\blade{A_r}$ is a subspace of $\blade{B_s}$ then $\blade{A_r}\blade{B_s} = \blade{A_r}\rfloor \blade{B_s}$.
        \item If $\blade{A_r}$ and $\blade{B_s}$ are orthogonal, then $\blade{A_r}\blade{B_s} = \blade{A_r} \wedge \blade{B_s}$.
    \end{itemize}
\end{itemize}

We also have the equivalences
\begin{equation}
\label{eq:left_contraction_dot}
A_r \cdot B_s \equiv A_r \rfloor B_s \qquad \textrm{if $k\leq s$}
\end{equation}
\begin{equation}
\label{eq:right_contraction_dot}
A_r \cdot B_s \equiv A_r \lfloor B_s \qquad \textrm{if $k\geq s$}.
\end{equation}
For homogeneous $r$-vectors $A_r$ and $B_r$, the products above simplify to 
\begin{equation}
\label{dot_equivalent_contraction}
    A_r \cdot B_r \equiv A_r \lfloor B_r \equiv A_r \rfloor B_r.
\end{equation}
In fact, if we are given two $r$-blades $\blade{A_r} = \blade{a_1} \wedge \cdots \wedge \blade{a_r}$ and $\blade{B_r} = \blade{b_1} \wedge \cdots \wedge \blade{b_r}$ we have the 
\begin{equation}
\label{eq:dot_product}
\blade{A_r} \cdot \blade{B_r}^\dagger = \det(\blade{a_i} \cdot \blade{b_j} )_{i,j=1}^r = \blade{A_r}^\dagger \cdot \blade{B_r},
\end{equation}
which is the typical extension of the inner product $g$ to an inner product on $\bigwedge^r (V)$ through linearity.

Given the direct relationship between unit $r$-blades and $r$-dimensional subspaces we can also form a compact way of projecting multivectors into subspaces in a manner closely related to the subspace dual.  \begin{definition}
Given an multivector $B$, the \emph{projection} onto the subspace $\blade{A_r}$ is
\begin{equation}
\label{eq:projection}
\projection_{\blade{A_r}}(B) \coloneqq B\rfloor \blade{A_r} \blade{A_r}^{-1} \equiv (B\rfloor \blade{A_r})\rfloor \blade{A_r}^{-1}
\end{equation}
\end{definition}
Following this definition, one can see that
\begin{equation}
\projection_{\blade{A_r}}(B) \in \bigoplus_{j=0}^r \G^j = \G^{0+\cdots + r},
\end{equation}
since the subspace $\blade{A_r}$ is $r$-dimensional and moreover the operation preserves grades since
\begin{equation}
\projection_{\blade{A_r}}(\proj{j}{B}) \in \G^j.
\end{equation}
For example, given vectors $\blade{u}$ and $\blade{v}$ we retrieve the familiar statement 
\begin{equation}
\projection_{\blade{u}} (\blade{v}) = (\blade{v} \cdot \blade{u}) \frac{\blade{u}}{|\blade{u}|^2}.
\end{equation}

A dual notion exists as well; we can project onto the subspace perpendicular to $\blade{A_r}$.
\begin{definition}
Given a multivector $B$, the \emph{rejection} from the subspace $\blade{A_r}$ is
\begin{equation}
\label{eq:rejection}
\rejection_{\blade{A_r}}(B) \coloneqq B \wedge \blade{A_r} \blade{A_r}^{-1} \equiv (B\wedge \blade{A_r})\lfloor \blade{A_r}^{-1}.
\end{equation}
\end{definition}
Note that this operation is also grade preserving. In the case we have a blade $\blade{C_k}$ with $k<r$ and $k<n-r$, we can note
\begin{equation}
\label{eq:projection+rejection_blade}
\blade{C_k}=\projection_{\blade{A_r}}(\blade{C_k}) + \rejection_{\blade{A_r}}(\blade{C_k}).
\end{equation}
Another useful result follows.
\begin{proposition}
Let $\G$ come with a positive definite $g$, let $\blade{A_{n-1}}$ unit pseudovector, and let $\blade{B_r}$ be an $r$-vector for $r\leq n-1$. Then,
\begin{equation}
|\blade{B_r}| = \left|\projection_{\blade{A_{n-1}}} (\blade{B_r})\right| + \left|\projection_{\blade{A_{n-1}}}(\blade{B_r}^\perp)^\perp\right|.
\end{equation}
\end{proposition}
\begin{proof}
Take an orthonormal basis $\blade{e}_1,\dots,\blade{e}_n$ for $\G$. Let $J$ be an increasing index set of length $r$, i.e., $J=\{j_1,j_2,\dots,j_r\}$ with $1\leq j_1 < j_2 <\cdots < j_r < n$ and define $\blade{E}_J = \blade{e}_{j_1}\blade{e}_{j_2}\cdots \blade{e}_{j_r}$ with $r\leq n-1$. Then note that any unit pseudovector $\blade{A_{n-1}}$ is a blade and so we can put $\blade{A_{n-1}} = \normal^\perp$ for some unit vector $\normal$.
Note that if $J$ contains $k$ then $\projection_{\blade{A_{n-1}}}(\blade{E}_J)$ is zero and otherwise this product is the identity since $\blade{E}_J$ lies in the subspace of $\blade{A_{n-1}}$. Next,
\begin{align}
\projection_{\blade{A_{n-1}}}(\blade{E}_J^\perp)^\perp &= \left( \blade{E}_J^\perp \rfloor \blade{A_{n-1}} \blade{A_{n-1}}^{-1}\right)^\perp\\
&= \blade{E}_J^\perp \rfloor \blade{A_{n-1}} (\normal \pseudoscalar^{-1})^{-1} \pseudoscalar^{-1}\\
&= (-1)^{n-1} \blade{E}_J^\perp \rfloor (\normal^\perp) \normal\\
&= (-1)^{n-1} (\blade{E}_J^\perp \wedge \normal )^\perp \normal\\
&= (-1)^{(r+1)(n-1)}(\normal \wedge \blade{E}_J^\perp)^\perp \normal\\
&= (-1)^{(n-1)(n+2r+2)/2} (\normal \rfloor \blade{E}_J) \normal.
\end{align}
Note that if $J$ does not contain $k$, then $\normal \rfloor \blade{E}_J=0$ and otherwise the product is the identity up to sign. 

Since this holds for $\blade{E}_J$, we note that we can write $B = \sum_J B_J \blade{E}_J$ so that $B$ is a sum of these basis blades. By linearity of $\projection$, we have proven the proposition.
\end{proof}
\todo{This proof may be true for multivectors not just $r$-vectors. Also, it may be better to say $|\projection_{\blade{A_{n-1}}}(B^\perp)|$ instead and use chisolm 187.}
The projection and rejection provide us a way to revisit the geometric notions of the interior and exterior products. In particular, we note that
\begin{align}
\label{eq:projection_inner_product}
    B \rfloor \blade{A_r} &= \projection_{\blade{A_r}} (B) \blade{A_r}\\
    B \wedge \blade{A_r} &= \rejection_{\blade{A_r}}(B) \blade{A_r}.
\end{align}
Both the notion of projection and rejection prove to be useful and behave nicely with the dual by
\begin{equation}
\label{eq:projection_rejection_duality}
\projection_{\blade{A_r}^\perp}(B) = \rejection_{\blade{A_r}}(B).
\end{equation}
\todo{prove this.}
Finally, the exterior product of orthogonal blades gives us a direct sum of subspaces in the following sense. Let $\blade{A_r}$ and $\blade{B_s}$ be orthogonal so that $\blade{A_r}\wedge \blade{B_s}=\blade{A_r}\blade{B_s}$, then we can note that if $k<r$ and $k<s$ we have
\begin{equation}
\label{eq:projection_sum_of_subspaces}
    \projection_{\blade{A_r}\wedge \blade{B_s}} (\blade{C_k}) = \projection_{\blade{A_r}}(\blade{C_k}) + \projection_{\blade{B_s}}(\blade{C_k}).
\end{equation}
Perhaps it is most enlightening for the reader to revisit \cref{eq:projection+rejection_blade,eq:projection_sum_of_subspaces} replacing $\blade{C_k}$ with a vector $\blade{v}$ since a vector will always prove to be a representative for a ``small enough" subspace.


\subsection{Motivating example}
\label{subsec:motivating_example}

Rather than a sequence of multiple examples, it will prove to be far more illuminating to construct one large example for which most of the preliminaries to this point can be used in a meaningful way. As such, we shall not rule out the utility of geometric algebras with pseudo inner products. The classical example is the \emph{spacetime algebra} defined by taking $V=\R^4$ with a vector basis $\blade{\gamma}_0,\blade{\gamma}_1,\blade{\gamma}_2,\blade{\gamma}_3$ satisfying
\begin{subequations}
\begin{align}
\blade{\gamma}_0 \cdot \blade{\gamma}_0 &= -1\\
\blade{\gamma}_0 \cdot \blade{\gamma}_i &= 0  &i=1,2,3\\
\blade{\gamma}_i \cdot \blade{\gamma}_j &= \delta_{ij}, &i,j=1,2,3.
\end{align}
\end{subequations}
Where $\blade{\gamma}_0$ is temporal since its square is negative and $\blade{\gamma}_i$ for $i=1,2,3$ are all spatial since their squares are positive. For this basis, we can denote the matrix for this inner product $\eta =\operatorname{diag}(-+++)$ (often called the \emph{Minkowski metric}) and define $Q$ from $\eta$. Then, we have for a spacetime vector $\blade{v} = v_0 \blade{\gamma}_0 +v_1 \blade{\gamma}_1 + v_2 \blade{\gamma}_2 + v_3 \blade{\gamma}_3$,
\begin{equation}
\label{eq:spacetime_inner_product}
|\blade{v}| = \blade{v} \cdot \blade{v} = -v_0^2 + \sum_{i=1}^3 v_i^2,
\end{equation}
which defines the algebra $\G_{1,3}$ as the spacetime algebra. The reader may now wish to, for example, revisit \cref{subsubsec:reverse_inverse_clifford_spin_groups} with $\G_{p,q}$ in mind in order to see a realization of the groups $\operatorname{SO}(p,q)$, $\operatorname{Spin}(p,q)$, and the spacetime spinors. 

As the naming above suggests, the geometric algebra of Euclidean space, $\G_3$, should naturally inside of the spacetime algebra. Note that we have the \emph{spatial pseudoscalar} $\blade{I}_S \coloneqq \blade{\gamma}_1 \wedge \blade{\gamma}_2 \wedge \blade{\gamma}_3$, which, allowing for an extension of our notion of projection to the whole algebra, allows us to put
\begin{equation}
\projection_{\blade{I}_S}(\G_{1,3}) \equiv \rejection_{\blade{\gamma}_0} (\G_{1,3}) = \G_3.
\end{equation}
Perhaps one could refer to this mapping as the \emph{static map} as we project only onto the spatial subspace and, via duality, reject the temporal subspace. It is also worth noting that this static map is not just producing an isomorphic copy of $\G_3$, but a a copy of $\G_3$ directly. Now, in $\G_3$, we can specify an arbitrary multivector $A$ by
\begin{equation}
A= a_0 + a_1 \blade{\gamma}_1 + a_2 \blade{\gamma}_2 + a_3 \blade{\gamma}_3 + a_{12} \blade{B}_{12} + a_{13} \blade{B}_{13} + a_{23} \blade{B}_{23} + a_{123} \blade{\gamma}_1 \wedge \blade{\gamma}_2 \wedge \blade{\gamma}_3,
\end{equation}
and so the grade projections read
\begin{subequations}
\begin{align}
\proj{}{A}&=a_0\\
\proj{1}{A}&=a_1 \blade{\gamma}_1 + a_2 \blade{\gamma}_2 + a_3 \blade{\gamma}_3\\
\proj{2}{A}&=a_{12} \blade{B}_{12} + a_{13} \blade{B}_{13} + a_{23} \blade{B}_{23}\\
\proj{3}{A}&= a_{123} \blade{\gamma}_1 \wedge \blade{\gamma}_2 \wedge \blade{\gamma}_3.
\end{align}
\end{subequations}
Then, we can write a even multivector as
\begin{equation}
q = q_0 + q_{23}\blade{B}_{23} + q_{31} \blade{B}_{31} + q_{12} \blade{B}_{12}.
\end{equation}
Note as well that
\begin{subequations}
\begin{align}
\blade{B}_{23}^2 = \blade{B}_{31}^2 = \blade{B}_{12}^2 &= -1\\
\blade{B}_{23}\blade{B}_{31}\blade{B}_{12} &= +1,
\end{align}
\end{subequations}
which is typical for spatial bivectors. In this case, one may notice that this even subalgebra is extremely close to being a copy of the quaternion algebra $\quat$. One can arrive at a representation of the quaternions by taking
\begin{equation}
\boldsymbol{i} \leftrightarrow \blade{B}_{23}, \quad \boldsymbol{j} \leftrightarrow -\blade{B}_{31}=\blade{B}_{13}, \quad \boldsymbol{k} \leftrightarrow \blade{B}_{12},
\end{equation}
and noting that we then have $\boldsymbol{ijk}=-1$ as well as $\boldsymbol{i}^2=\boldsymbol{j}^2=\boldsymbol{k}^2=-1$. A more in depth explanation is provided in \cite{doran_geometric_2003}. Thus, we realize a quaternion as a spinor $q$ and a purely imaginary quaternion is simply the grade-2 portion of the spinor $\proj{2}{q}$. We also realize $\quat$ as scalar copies of elements of $\operatorname{Spin}(3) \cong \operatorname{Sp}(1)$. That is to say that $\quat \cong \R \times \operatorname{Spin}(3)$. Indeed, since elements of $\G_3^+$ are simply surface spinors, the surface spinors admit a natural spin representation.

But we are not done here, and we can project down one dimension further by
\begin{equation}
    \projection_{\blade{\gamma}_1 \wedge \blade{\gamma}_2} (\G_3) = \G_2.
\end{equation}
To see this in action, we let $\blade{v}=v_1 \blade{\gamma}_1 + v_2 \blade{\gamma}_2 + v_3 \blade{\gamma}_3$
\begin{subequations}
\begin{align}
    \projection_{\blade{\gamma}_1 \wedge \blade{\gamma}_2} = \projection_{\blade{B}_{12}} (\blade{v}) &= (v_1 \blade{\gamma}_1 + v_2 \blade{\gamma}_2 + v_3 \blade{\gamma}_3)\rfloor \blade{B}_{12}\blade{B}_{12}^{-1}\\
    &= (v_1 \blade{\gamma}_2 - v_2 \blade{\gamma}_1)\blade{B}_{12}^{-1} \\
    &= v_1 \blade{\gamma}_1 + v_2 \blade{\gamma}_2.
\end{align}
\end{subequations}
Then, arbitrary multivectors $A$ and $B$ can be specified by
\begin{equation}
A = a_0 + a_1 \blade{\gamma}_1 + a_2 \blade{\gamma}_2 + a_{12} \blade{B}_{12}, \qquad B = b_0 +b_1 \blade{\gamma}_1 + b_2 \blade{\gamma}_2 + b_{12}\blade{B}_{12}.
\end{equation}
We can then take the product $AB$ to yield
\begin{subequations}
\begin{align}
\proj{0}{AB} &= a_0b_0 + a_1 b_1 + a_2 b_2 - a_{12}b_{12}\\
\proj{1}{AB} &= (a_0 b_1 + a_1 b_0 - a_2 b_{12} + a_{12} b_2) \blade{\gamma}_1 + (a_0 b_2 + a_2 b_0 + a_1b_{12} - a_{12} b_1) \blade{\gamma}_2\\
\proj{2}{AB} &= (a_1b_2 - a_2 b_1)\blade{B}_{12}.
\end{align}
\end{subequations}
Most notably, we see that $\blade{B}_{12}^2=-1$ and this allows us to consider a spinor
\begin{equation}
z = x + y \blade{B}_{12}
\end{equation}
which is exactly a representation of the complex number $\zeta = x+ iy$ in $\G_2^{0+2}=\G_2^+$.  Thus, the even subalgebra of this geometric algebra is indeed isomorphic to the complex numbers $\C$. Indeed, there is one unit 2-blade $\blade{B}_{12}$ in $\G_2$ to form the spin algebra $\mathfrak{spin}(2) \cong \R$ and as a consequence all unit norm elements in $\G_2^+$ can be written as
\begin{equation}
   e^{\theta \blade{B}_{12}} = \sum_{n=0}^\infty \frac{\theta \blade{B}_{12}}{n!} = \cos(\theta)+\blade{B}_{12}\sin(\theta),
\end{equation}
where $\theta \blade{B}_{12}$ is a general bivector in $\G_2$ when $\theta \in \R$ is arbitrary. Hence, we arrive at $\operatorname{Spin}(2)\cong \operatorname{U}(1)$. Any element in $\C$ is also a scaled version of an element of the spin group $\operatorname{Spin}(2)$. Hence, we can use a spin representation for an element in $\C$ via $z=re^{\theta \blade{B}_{12}} \in \R\times \operatorname{Spin}(2)$.  This special case shows that spinors in $\G_2$ have a unique spin representation.

But, the above work is not necessary special to the starting point of $\G_{1,3}$ or $\G_3$. In fact, if we take $\G_n$ for $n\geq 2$, then there are natural copies of $\C$ contained inside of $\G_n$. In particular, we have the isomorphism
\begin{equation}
\label{eq:c_isomorphisms}
    \C \cong \{x + y \blade{B} ~\vert~ x,y \in \G_n^0,~ \blade{B} \in \Grassmannian{2}{n}. \},
\end{equation}
which shows that complex numbers arise as surface spinors via the representation
\begin{equation}
        \zeta = x + y\blade{B},
\end{equation}
since $\blade{B}^2=-1$. Given the standard basis $\blade{e_1},\dots,\blade{e_n}$ we have copies of $\C$ for each of the ${ n \choose 2}$ unit bivectors $\blade{B}_{jk}$ with $k=2,\dots,n$ and $j<k$.

\subsection{Geometric manifolds}
We want to generalize the setting of geometric algebra to include a smooth structure. For instance, we can consider a manifold $M$ (likely with boundary $\partial M$) with a metric structure and develop a geometric algebra at each tangent space to this manifold (e.g., following \cite{schindler_geometric_2020}). We refer to this as the \emph{geometric tangent space} and put $C\ell(T_xM,g_x)$.
\begin{definition}
A manifold $M$ with a pseudo-Riemannian metric $g$ is a \emph{geometric manifold} if each tangent space is a geometric tangent space.
\end{definition}
On geometric manifolds we will be able to attach multivector fields and compute their derivatives as well as integrate. This leads us to the realm of geometric calculus and Cifford analysis. Geometric calculus is intimately related to both the vector calculus in $\R^3$ and differential forms. It has the added advantage of notational convenience and clarity as we have seen with geometric algebra and its subspace operations. In the beginning of \cref{subsec:clifford_and_geometric_algebras} we realize as well that the exterior algebra is contained inside any Clifford algebra and, to this end, geometric calculus will contain the calculus of differential forms. 

Forms are a useful language for proving general theorems about boundary value problems \cite{schwarz_hodge_1995}, and so we will retrieve all of these theorems for our own utility. Given that we have increased geometrical intuition on different graded elements of a geometric algebra, we can realize that we can work with multivector equivalents of forms instead of concentrating on forms of a specific grade. For example, in \cref{subsec:forward_problems} we see that one can think of the electromagnetic field as a multivector consisting of elements of various degree as opposed to the usual field strength 2-form \cite{warnick_dierential_2014}. In fact, under certain other restrictions such as those present in Ohmic materials, we find there are surface spinors that fall into the kernel of a Dirac-type operator.

This Dirac-type operator, $\grad$, is the grade-1 derivative operator studied in Clifford analysis. Fundamentally, this operator generalizes the Wirtinger derivative for complex functions to multivectors and, as such, generalizes the notion of a $\C$-holomorphic function to that of a monogenic function (see \todo{refence later}). Happily, we even retain a Taylor series representation (see \cref{lem:density}) for functions in the kernel of $\grad$ due to a generalized form of the Cauchy integral formula. This Cauchy integral formula has been applied elsewhere (see \cite{brackx_hilbert_2008}). The Cauchy integral also provides a direct correspondence between smooth functions defined on the boundary $\partial M$ of a manifold $M$. 

\subsection{Multivector fields}

In order to develop fields on a geometric manifold we must first create the relevant bundle structure. There is a natural bundle associated to a  geometric manifold given by by gluing together each of the tangent geometric algebras. The \emph{geometric algebra bundle} of a geometric manifold $(M,g)$ is the space
\begin{equation}
\bigsqcup_{x \in M} C\ell(T_xM,g_x).
\end{equation}
Given this bundle, the fields follow.
\begin{definition}
A \emph{(smooth) multivector field} is a ($C^{\infty}$-smooth) section of the geometric algebra bundle. We put $\G(M)$ as the \emph{space of multivector fields on $M$}.
\end{definition}
Note that the we will assume that all multivector fields are $C^\infty$-smooth and drop this additional modifier when speaking of any type of multivector field. The above definition above is very general and we may not find ourselves working over arbitrary geometric manifolds. For example, we highlight a specific use case by letting $M$ be a connected region of $\R^n$. For brevity, we will put $\mathcal{G}_n(M)$ to denote we are working over a region $M\subseteq \R^n$. In this case, the multivectors themselves are realized as constant multivector fields which allows us to say $\G_n \subset \G_n(M)$. This smooth setting simply makes the coefficients of the global basis blades given by $C^\infty$ functions as opposed to $\R$ scalars.  Hence, $\G_n(M)$ is simply the $C^{\infty}$-module equivalent of $\mathcal{G}_n$.

Perhaps the $C^\infty$-module structure obfuscates the point slightly, but the notion of a smooth section does not.  One should think of the fields in $\G_n(M)$ as multivector valued functions on $M \subset \R^n$. Taking this identification allows for an extended toolbox at our disposal. In particular, points in $M$ are uniquely identified with constant vector fields in $\G_n^1$ and one can consider endomorphisms living in $\G_n$ (acting on $\G_n^1$) as acting on the input of fields in $\G_n(M)$ as well (see \cref{rem:input_projection}).  Thus, there is not only an algebraic structure on the fields themselves, but on the point in which the field is evaluated.  This is perhaps the key insight on why authors developed the so-called vector manifolds widely used in the geometric algebra landscape. Fundamentally, this is true in all local coordinates for an arbitrary manifold $M$, but it is not a global phenomenon since, for example, not all manifolds admit everywhere smooth nonzero constant vector fields. Just take the 2-sphere, $M=S^2$, and note the hairy ball theorem.

\begin{remark}
\label{rem:input_projection}
    If we consider a multivector field $f \in \G_n(\R^n)$. With $x\in \R^n$ being identified with the vector $\blade{x} \in \G_n^1$, we can safely put $f(\blade{x})$.  One may be interested in the restriction of the input of $f$ to a subspace $\blade{U_r}$ which yields $f(\projection_{\blade{U_r}}(\blade{x}))$.  
\end{remark}

As noted throughout \cref{subsec:clifford_and_geometric_algebras}, there are spaces of multivectors inside $\G$ of interest and each of these extends to their field counterpart. Construction of each is done pointwise and made global through the relevant bundle. Let us list the relevant spaces of fields.
\begin{itemize}
    \item The \emph{$r$-vector fields},
    \begin{equation}
        \G^r(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{x \in M} C\ell(T_xM,g_x)^r\right\}; 
    \end{equation}
    \item The \emph{spinor fields},
    \begin{equation}
        \G^+(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{x \in M} C\ell(T_xM,g_x)^+\right\};
    \end{equation}
    \item The \emph{surface spinor fields},
    \begin{equation}
        \G^{0+2}(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{x \in M}  C\ell(T_xM,g_x)^{0+2}\right\};
    \end{equation}
%    \item The \emph{Clifford fields},
%    \begin{equation}
%        \G^r(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{p \in M} \Gamma(C\ell(T_pM,g_p))\right\};
%    \end{equation}
%    \item The \emph{spin group fields},
%    \begin{equation}
%        \G^r(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{p \in M} \operatorname{Spin}(T_pM)\right\};
%    \end{equation}
%    \item The \emph{spin algebra fields},
%    \begin{equation}
%        \G^r(M) \coloneqq \left\{\textrm{smooth sections of } \bigsqcup_{p \in M} \mathfrak{spin}(T_pM)\right\};
%    \end{equation}
\end{itemize}
Our operations from \cref{subsec:clifford_and_geometric_algebras} carry over. We simply define all the products seen in \cref{eq:dot,eq:wedge,eq:left_contraction,eq:right_contraction} to act pointwise in each geometric tangent space. Previously we referred to $r$-blades as special $r$-vectors. Thus, we realize an $r$-blade field $\blade{A_r} \in \G^r(M)$ assumes the same form of \cref{eq:blade} where the vectors $\blade{v}_j$ are to be understood as vector fields for which all $\blade{v}_j(x)$ are linearly independent in $T_xM$ at the point $x$.

Given local coordinates $x^i$ on $M$ containing the point $p$, the tangent vectors in a neighborhood about $p$ are induced from the coordinates by $\frac{\partial}{\partial x^i}$. However, this choice of basis may be canonical, but it is not arbitrary. Instead, at each point we can simply choose an arbitrary local vector basis $\blade{v}_i$ and let the components of the metric be given in this basis by $g_{{ij}(x)} = \blade{v}_i(x)\cdot \blade{v}_j(x)$. From here, we can suppress the pointwise notion and instead just put $g_{ij}=\blade{v}_i\cdot \blade{v}_j$ locally. This allows us to work notationally with bases in a global manner without any reference to coordinates, so long as we assume the understanding is clear -- these vector bases do only exist locally. If explicit computations are to be carried out, one can just take the canonical basis so that $\blade{v}_i=\frac{\partial}{\partial x^i}$. Thus, locally we have the reciprocal basis $\blade{v}^i=g^{ij}\blade{v}_j$, the reverse $\dagger$, dual $\perp$, projection $\projection$, and rejection $\rejection$ that act on multivector fields pointwise in $C\ell(T_xM,g_x)$ and, if the need arises, all computations can be done in local coordinates. 

\subsection{Geometric calculus}

On $M$ we have the unique torsion free Levi-Civita connection $\nabla$ for which we can define the covariant derivative $\nabla_{\blade{u}}$ for a vector field $\blade{u}$. The covariant derivative is extended to act on multivector fields following \cite{schindler_geometric_2020}. We can note that $\nabla_{\blade{u}}$ is a grade preserving differential operator so that
\begin{align}
    \nabla_{\blade{u}} \proj{r}{A_r} = \proj{r}{\nabla_{\blade{u}} \proj{r}{A_r}},
\end{align}
and it is a dot-compatible and wedge-compatible operator since
\begin{align}
    \nabla_{\blade{u}} (A\cdot B) &= (\nabla_{\blade{u}} A) \cdot B + A \cdot (\nabla_{\blade{u}} B)\\
    \nabla_{\blade{u}} (A\wedge B) &= (\nabla_{\blade{u}} A) \wedge B + A \wedge (\nabla_{\blade{u}} B)
\end{align}
\begin{definition}
    Let $\blade{v}_i$ be an arbitrary basis, then the \emph{gradient} (or \emph{Dirac operator}) $\grad$ is defined by
\begin{equation} 
\grad = \sum_{i} \blade{v}^i \nabla_{\blade{v}_i}.
\end{equation}
\end{definition}
The space of multivector fields $\G(M)$ along with $\grad$ is usually referred to as geometric calculus. One should note that $\grad$ is acts as a grade-1 element. Thus, the gradient splits into two operators, 
\begin{align}
\grad \rfloor &\colon \G_n^r(M) \to \G_n^{r-1}(M), \\
\grad \wedge &\colon \G_n^r(M) \to \G_n^{r+1}(M),
\end{align}
which satisfy the properties
\begin{align}
\label{eq:differential_properties}
(\grad \wedge)^2=0,\\
(\grad \rfloor)^2 = 0,
\end{align}
when acting on a homogeneous $r$-vector. Since \ref{eq:differential_properties} holds, the gradient operator gives rise to the grade preserving \emph{Laplace-Beltrami operator}
\[
\Delta = \grad^2 = \grad \rfloor \circ \grad \wedge + \grad \wedge \circ \grad \rfloor,
\]
which is manifestly coordinate invariant by definition.  It also motivates the use of the physicist notation $\grad^2=\Delta$, but we do not adopt this here.  We refer to multivector fields $f$ in the kernel of the Laplace-Beltrami operator \emph{harmonic multivector fields} or simply as \emph{harmonic}.

Note that since Euclidean space $\R^n$ has global orthonormal coordinates $\blade{e}_i$ we can choose a global constant vector field basis since we identified $\G_n^1$ with $\G(\R^n)^1$. With respect to these fields, we have the that $\nabla_{\blade{u}}$ reduces to the directional derivative. Note then that $\blade{u} \cdot \grad = \nabla_{\blade{u}}$ defines the directional derivative via the gradient. In fact, given a subspace $\blade{U_r}$, one could even describe a derivative in $\blade{U_r}$ by $\projection_{\blade{U_r}}(\grad)$.

There exists a Leibniz rule for $\grad$ as well given by
\begin{equation}
\grad(AB) = \grad A B + \dot{\grad}A\dot{B},
\end{equation}
where we use the overdot to signify which multivector field we are taking derivatives of. The Clifford product, however, does not change. 

\subsection{Differential forms}
\label{subsec:differential_forms}

The language of differential forms \cite{guillemin_differential_2010} rests neatly inside geometric calculus. We will develop the relationship between multivectors and forms which will serve as a link between the two notions so that researchers with interest in Clifford analysis can communicate with those who study forms. In order to do so, we appeal to the language of differential forms and build a relationship between multivector fields and forms through measures. Forms have their appeal in global understanding via their properties through integration (e.g., Stokes' and Green's theorems) and the exterior calculus along with de Rham cohomology will provide us a larger toolbox.

Given coordinates $\blade{x}=(x_1,x_2,\dots,x_n)$ on $M$ we have the local basis tangent vector fields $\blade{v}_i=\frac{\partial \blade{x}}{\partial x_i}$  with the corresponding 1-forms $dx^i$ that are each local sections of $T^*M$ and are the exterior derivatives (or gradients) of the coordinate functions.  1-forms are linear functionals on tangent vectors and in these coordinates we have $dx^i  (\blade{v}_i) = \delta^i_j$ and one can thus take a pairing of 1-form fields and vector fields and integrate over 1-dimensional submanifolds. The benefit of this definition is that the 1-forms $dx^i$ carry a natural measure and we can form product measures via the exterior product $\wedge$.

On $M$, we let $\Omega(M)$ be the exterior algebra of smooth form fields on $M$, and let $\Omega^r(M)$ be the space of smooth $r$-form fields on $M$. Then we have the Riemannian volume measure $\mu \in \Omega^n(M)$ given in local coordinates by
\begin{equation}
\mu = \sqrt{|g|} dx^1\dots dx^n.
\end{equation}
\begin{definition}
The \emph{$r$-dimensional directed measure} $dX_r$ is given in local coordinates by
\begin{equation}
    dX_r \coloneqq \blade{v}_{i_1} \wedge \cdots \wedge \blade{v}_{i_r} dx^{i_1} \cdots dx^{i_r}. 
\end{equation}
\end{definition}
For example, along a 2-dimensional submanifold we have the 2-dimensional directed measure 
\begin{equation}
    dX_2 = \blade{v}_i \wedge \blade{v}_j dx^i dx^j
\end{equation}
and we can note that 
\begin{equation}
(\blade{v}^i \wedge \blade{v}^j)\cdot dX_2^\dagger = dx^idx^j - dx^j dx^i
\end{equation}
is completely antisymmetric and provides us a surface measure we can integrate; this is a differential 2-form. We then find that
\begin{equation}
\label{eq:volume_form}
\mu = \blade{I}^{-1} \cdot dX_n = \blade{I}^{-1} dX_n = \blade{I}^{-1 \dagger} \cdot dX_n^\dagger = 1^\perp \cdot dX_n,
\end{equation}
where $\blade{I}$ is the unit pseudoscalar field defined on $M$ with respect to $g$. The last of the equalities above is quite important. It seeks to tell us that, morally, many of our familiar statements about integrals will involve the dual.

We can now write a $r$-form $\alpha_r = \alpha_{i_1 \cdots i_r} dx^{i_1}\wedge \cdots dx^{i_r}$ as 
\begin{equation}
\alpha_r = A_r \cdot dX_k^\dagger,
\end{equation}
where
\begin{equation}
A_r = \frac{1}{r!} \alpha_{i_1 \cdots i_r} \blade{v}^{i_1} \wedge \cdots \wedge \blade{v}^{i_r}.
\end{equation}
We refer to $A_r$ as the \emph{multivector equivalent} of $\alpha_r$ and note that by \cref{eq:volume_form} that the multivector equivalent to $\mu$ is $\pseudoscalar^{-1 \dagger}$. This provides an isomorphism between $r$-forms and $r$-vectors via a contraction with the $r$-dimensional volume directed measure. In this sense, a differential form is made up of two essential components namely the multivector field and the $r$-dimensional directed measure. Hence, we can see now how a differential form simply appends the measure attached to the underlying space. We can also see how this generalizes the musical isomorphism $\flat$ by taking a vector field $\blade{v}$ and noting
\begin{equation}
\label{eq:line_element}
\blade{v} \cdot dX_1 = v_i  \blade{v}_i \cdot \blade{v}^j dx^j = v_i dx^i.
\end{equation}

The exterior algebra of differential forms comes with an addition $+$ and exterior multiplication $\wedge$.  We note that the sum of two $r$-forms $\alpha_r$ and $\beta_r$ is also a $r$-form which we can see reduces to addition on the multivector equivalents $A_r$ and $B_r$ by
\begin{equation}
\alpha_r + \beta_r = (A_r \cdot dX_r^\dagger)+(B_r \cdot dX_r^\dagger) = (A_r + B_r) \cdot dX_r^\dagger,
\end{equation}
due to the linearity of $\cdot$.  If instead had an $s$ form $\beta_s$ then we have the exterior product
\begin{equation}
\alpha_r \wedge \beta_s = (A_r \wedge B_s) \cdot dX_{r+s}^\dagger,
\end{equation}
where $dX_{r+s}=0$ if $r+s>n$.  

With differential forms one also has the exterior derivative $d$ giving rise to the exterior calculus. On the multivector equivalents we have
\begin{equation}
d \alpha_r = (\grad \wedge A_r) \cdot dX_{r+1}^\dagger,
\end{equation}
which realizes the exterior derivative as the grade raising component of the gradient $\grad$. Of course, for scalar fields, this returns the gradient as desired. We will find $\grad \rfloor$ can be identified with the codifferential $\delta$ up to a sign. 

\subsection{Integration}
\label{subsec:integration_on_submanifolds}

Given a $r$-dimensional submanifold $R \subset M$ with a $r$-form $\alpha_r$ defined on $R$, we can integrate this $r$-form. However, we want to phrase this in terms of the the multivector equivalents.  First, we will do this for scalar valued integrals. 

\subsubsection{Scalar valued integrals}
Let $\mu_R$ be the volume measure for the submanifold $R$.  Given $R$ is a submanifold of $M$, for any $x \in R$ we have tangent space $T_x R$ which is a subspace of $T_x M$. Hence, we can put $\blade{I}_R(x)^{-1 \dagger}$ to be the multivector equivalent of $\mu_R$ by
\begin{equation}
\label{eq:submanifold_volume_form}
\mu_R = \blade{I}_R^{-1 \dagger} \cdot dX_r^\dagger = \blade{I}_R^{-1} \cdot dX_r.
\end{equation}
We should think of $\blade{I}_R^{-1 \dagger}$ as representing the subspace $T_x R \subset T_x M$ and note that we think of $\blade{I}_R^{-1 \dagger}$ as a unit pseudoscalar field defined on $R$. 

An $s$-vector field $A_s$ on $R$ is said to be \emph{tangent to $R$} if
\begin{equation}
A_s = \projection_{\blade{I}_R}(A_s)
\end{equation} 
so that for any $x \in R$ that $A_s = \operatorname{P}_{\blade{I}_R(x)}(A_s(x))$. Immediately we can conclude that we must have $s\leq r$ or this projection is zero (see \cref{subsubsec:blades_and_subspaces}). We may, for example, wish to integrate scalar fields $A_0$ over $R$ and in this case we can put $A_r = A_0 \blade{I}_R^{-1}$ and contract with $dX_r$ to create a tangent $r$-form on $R$ by 
\begin{equation}
\alpha_r = A_r \cdot dX_r^\dagger = A_0 \mu_R
\end{equation}
which can be integrated as
\begin{equation}
\int_K \alpha = \int_K A_0 \mu_R.
\end{equation}
This of course applies to scalar fields on $M$ itself, for which we can take $A_n = A_0 \blade{I}^{-1}$. Then this form can be integrated by
\begin{equation}
\int_M \alpha_n = \int_M A_0 \mu.
\end{equation}

There is also the normal space $N_x R$ that is everywhere orthogonal to $T_x R$ with respect to $g$ on $M$. This yields the normal $n-r$-blade field $\blade{\nu}_R = \blade{I}_R^\perp$. Since $R$ is a submanifold of $M$, we have the inclusion $\iota \colon R \to M$ and the induced pullback on forms $\iota^* \colon \Omega(M) \to \Omega(R)$. 
\begin{proposition}
Let $\alpha_s$ be an $s$-form defined on $M$ and let $\iota \colon R \to M$ be the inclusion of the submanifold $R$ into $M$. Then the pullback $\iota^*$ on the multivector equivalent $A_s$ is given by
\begin{equation}
\iota^* \alpha_s = \projection_{\blade{I}_R}(A_s) \cdot dX_s.
\end{equation}
\end{proposition}
\begin{proof}
Note that by definition we have
\[
(\iota^* \alpha_s)_x (\blade{v}_1,\dots,\blade{v}_r) = (\alpha_s)_x(d\iota_x\blade{v}_1,\dots, d\iota_x\blade{v}_r ),
\]
for arbitrary vector fields $\blade{v}_1,\dots,\blade{v}_s$ and at all $x\in R$. Then, since $\iota$ is inclusion, we have
\[
d\iota_x = \projection_{\blade{I}_R(x)},
\]
at each point $x \in R$ and hence
\[
\iota^* \alpha_s = \alpha_s \circ \projection_{\blade{I}_R}.
\]
For all $\blade{v}_i$ we can put
\[
\blade{v}_i = \projection_{\blade{I}_R}(\blade{v}_i) + \rejection_{\blade{I}_R}(\blade{v}_i),
\]
and note for the multivector equivalent
\begin{align}
\label{eq:previous_1}
(\projection_{\blade{I}_R}(A_s) \cdot dX_s)(\blade{v}_1,\dots,\blade{v}_s) &= (\projection_{\blade{I}_R}(A_s) \cdot dX_s)(\projection_{\blade{I}_R}(\blade{v}_1) + \rejection_{\blade{I}_R}(\blade{v}_1),\dots,\projection_{\blade{I}_R}(\blade{v}_s) + \rejection_{\blade{I}_R}(\blade{v}_s))\\
&= (\projection_{\blade{I}_R}(A_s) \cdot dX_s)(\projection_{\blade{I}_R}(\blade{v}_1),\dots,\projection_{\blade{I}_R}(\blade{v}_s)),
\end{align}
since $\projection_{\blade{I}_R}(A_s)$ is supported only on $R$. Then, if $s\leq r$,
\begin{align*}
\iota^*\alpha_s &= (A_s \cdot dX_s)(\projection_{\blade{I}_R}(\blade{v}_1),\dots,\projection_{\blade{I}_R}(\blade{v}_s))\\
&= ((\projection_{\blade{I}_R}(A_s) + \rejection_{\blade{I}_R}(A_s)) \cdot dX_s)(\projection_{\blade{I}_R}(\blade{v}_1),\dots,\projection_{\blade{I}_R}(\blade{v}_s))\\
&= (\projection_{\blade{I}_R}(A_s) \cdot dX_s)(\projection_{\blade{I}_R}(\blade{v}_1),\dots,\projection_{\blade{I}_R}(\blade{v}_s)),
\end{align*}
and by \cref{eq:previous_1} we have our intended result. If $s>r$, then 
\[
\iota^* \alpha_s = 0 = \projection_{\blade{I}_R}(A_s)
\]
which proves the proposition.
\end{proof}

The above seems to motivate the choice of \cite{schwarz_hodge_1995} to put $\tangent_R = \iota^*$ to refer to the tangential part of a differential form. The normal part of a form is $\mathbf{n}_R \alpha_s = \alpha_s - \tangent_R \alpha_s$. The following corollary is immediate given \cref{eq:projection_rejection_duality,eq:projection+rejection_blade}. 
\begin{corollary}
Let $\alpha_s$ be an $s$-form with $s<r$ and $s<n-r$ and multivector equivalent $A_s$. Then
\begin{equation}
\mathbf{n}_R \alpha_s = \alpha_s - \operatorname{P}_{\pseudoscalar_R}(A_s)\cdot dX_s^\dagger = \rejection_{I_R}(A_s)\cdot dX_s^\dagger.
\end{equation}
\end{corollary}

This is pertinent when we take $M$ to be a manifold with boundary $\partial M$. In this case we let $\blade{I}_\partial$ denote the tangent $n-1$-blade and build boundary measure via
\begin{equation}
\mu_\partial \coloneqq \blade{I}_\partial^{-1} \cdot dX_{n-1}.
\end{equation}
The normal space is 1-dimensional and we put $\blade{\nu}$ to refer to the boundary normal space. It is common to compute the flux of a vector field $\blade{v}$ through $\partial M$ by integrating $\projection_{\blade{\nu}}(\blade{v})$ over the boundary. However, the the vector field $\projection_{\blade{\nu}}(\blade{v})$ is the multivector equivalent of a 1-form. Hence, what we should have is a pseudovector $\projection_{\blade{I}_\partial}(\blade{v}^\perp)$ which is the equivalent to the $n-1$-form
\begin{equation}
\projection_{\blade{I}_\partial}(\blade{v}^\perp) \cdot dX_{n-1}^\dagger = (-1)^p \blade{v}\cdot \blade{\nu} \mu_\partial.
\end{equation}
This tells us that the flux is determined both by the vector field $\blade{v}$ and the local geometry of $\partial M$ captured by $\mu_\partial$. A proof follows. 
\begin{proposition}
\label{prop:flux}
Then the flux of a vector field $\blade{v}$ through $\partial M$ is
\begin{equation}
\int_{\partial M} \projection_{\blade{I}_\partial}(\blade{v}^\perp) \cdot dX_{n-1}^\dagger = (-1)^p\int_{\partial M} \blade{v} \cdot \blade{\nu} \mu_\partial,
\end{equation}
where $p$ is the number of temporal vectors in $\G(M)$.
\end{proposition}
\begin{proof}
Take
\begin{align*}
\projection_{\blade{I}_\partial}(\blade{v}^\perp) &= \blade{v}^\perp \rfloor \blade{I}_\partial \blade{I}_\partial^{-1}\\
    &= (\blade{v}^\perp \wedge \blade{\nu})^\perp \blade{I}_\partial^{-1}\\
    &= (-1)^{n-1} (\blade{\nu} \rfloor \blade{v})^{\perp \perp} \blade{I}_\partial^{-1}\\
    &= (-1)^{\frac{1}{2}(n+1)(n-1)+p} \blade{v}\cdot \blade{\nu} \blade{I}_\partial^{-1}\\
    &= (-1)^p \blade{v} \cdot \blade{\nu} \blade{I}_\partial^{-1 \dagger}.
\end{align*}
Hence 
\[
\projection_{\blade{I}_\partial}(\blade{v}^\perp) \cdot dX_{n-1}^\dagger =(-1)^p \blade{v} \cdot \blade{\nu} \mu_\partial.
\]
\end{proof}

For smooth $r$-forms $\alpha_r$ and $\beta_r$, we have an $L^2$-inner product 
\begin{equation}
\int_M \alpha_r \wedge \star \beta_r 
\end{equation}
where $\star$ is the Hodge star. By definition, the Hodge star acts on $r$-forms by returning a Hodge dual $n-r$-form so that on the multivector equivalents we have
\begin{equation}
\alpha_r \wedge \star \beta_r  = \proj{}{A_r B_r^\dagger}\mu = (A_r,B_R)\mu
\end{equation}
as well as
\begin{equation}
    \alpha_r \wedge \star \alpha_r = |A_r|^2\mu.
\end{equation}
For the action of $\star$ on the multivector equivalents we will put $B_r^\star$ for which we have
\begin{equation}
B_r^\star = (\pseudoscalar^{-1} B_r)^\dagger
\end{equation}
and we can quickly verify that
\begin{align}
(A_r \wedge B_r^\star)\cdot dX_n^\dagger = (A_r\cdot B_r^\dagger) \pseudoscalar^{-1 \dagger}\cdot dX_n^\dagger = \proj{}{A_rB_r^\dagger}\mu.
\end{align}
This allows us to define can now define an $L^2$ inner product on multivector fields.
\begin{definition}
\label{def:multivector_field_inner_product}
Let $A$ and $B$ be multivector fields. Then the \emph{multivector field inner product} is defined by
\begin{equation}
\multivecinnerproduct{A}{B} \coloneqq \frac{1}{\operatorname{vol}(M)} \int_M (A,B) \mu.
\end{equation}
\end{definition}
If $\multivecinnerproduct{A}{B} = 0$, then we say $A$ and $B$ are orthogonal. Once again, this is only a true inner product when $g$ is positive definite.  We put $\multivecinnerproduct{\cdot}{\cdot}_\partial$ to represent the inner product on the boundary manifold. Note that if we take a homogeneous $r$-vector field $A_r$ and $s$-vector field $B_s$ that if $s\neq r$, the multivector field inner product is zero. Hence, the orthogonal direct sum with respect to the $L^2$ multivector inner product agrees with the grade based direct sum. It will suffice to use the symbol $\oplus$ for both. One should view this as a slight extension to the $r$-form inner product that garners the ability to consider the inner product of elements that are not necessarily homogeneous in grade. The following proposition confirms this.
\begin{proposition}
Given two $r$-forms, the $r$-form inner product is equal to the multivector inner product on their corresponding multivector equivalents up to the constant $\operatorname{vol}(M)$.
\end{proposition}
\begin{proof}
Let $\alpha_r$ and $\beta_r$ be $r$-forms with multivector equivalents $A_r$ and $B_r$ respectively. Then
\begin{align*}
    \int_M \alpha_r \wedge \star \beta = \int_M A_r \cdot B_r^\dagger \mu = \int_M \proj{}{A_r^\dagger B_r} \mu =\operatorname{vol}(M) \multivecinnerproduct{A_r}{B_r},
\end{align*}
by the definition of the Hodge star.
\end{proof}


\subsubsection{Multivector valued integrals}

The integrals defined before allow us to encapsulate integration via differential forms, but geometric calculus allows for an extension to multivector valued integrals. Examples using kernel functions are prevalent in physics. Take for instance, determining a magnetic field from a charge distribution or the Biot-Savart law to determine a magnetic field from a current distribution. No drastic changes are needed to our previous formulation. 

Let $A\in \G(M)$ be a multivector field and take a submanifold $R\subset M$. Then, we can define a multivector valued integral by
\begin{equation}
\int_R A \pseudoscalar_R \mu_R.
\end{equation}
The benefit here is more pronounced in \cref{subsec:ftgc}. For example, this notion allows us to define multivector fields via integration. It will lead us to \cref{eq:cauchy_integral}.


%Two subsets of fields may be orthogonal with respect to the scalar valued Clifford inner product, but they may fail to be Clifford orthogonal. In fact, the grade based decomposition does not hold over the multivector field inner product. For example, consider $M$ a region of $\R^n$ then $\G_n(M)$ and take a constant subspace (unit blade) $\blade{B}_{12}$ and a blade inside this subspace $\blade{e}_2$ then
%\begin{equation}
%\multivecinnerproduct{\blade{B}_{12}}{\blade{e}_2} = \int_M  \blade{e}_1 \mu = \blade{e}_1 \textrm{vol}(M),
%\end{equation}
%which shows the fields $\blade{B}_{12}$ and $\blade{e}_2$ are not Clifford orthogonal.
%\todo{this is kind of interesting. It seems to say that the inner product value is almost describing how the vectors differ and by how much of $M$ they differ by...?}
%We extend the notion of Clifford orthogonal to spaces. That is, if we have a space of multivector fields $X$ and another space of multivector fields $Y$ such that for any $A\in X$ and $B\in Y$ we have $\multivecinnerproduct{A}{B}=0$ then we say $X$ and $Y$ are Clifford orthogonal and we put $X \boxplus Y$ to refer to the orthogonal direct sum with respect to the Clifford inner product.




\subsection{Stokes' and Green's formula}

With forms, we have a compact form of Stokes' theorem given by
\begin{equation}
\int_M d \alpha_{n-1} = \int_{\boundary} \iota^* \alpha_{n-1},
\end{equation}
for sufficiently smooth $n-1$-forms $\alpha_{n-1}$. This theorem can be applied to submanifolds $R$ of $M$ as well, just with $r-1$-forms. For example, if $M\subset \R^3$ is a 2-dimensional submanifold of $\R^3$, then one retrieves the Stokes' theorem in vector calculus. \cref{subsec:differential_forms,subsec:integration_on_submanifolds} allows us to determine this in terms of the multivector equivalents. We have the multivector version of Stokes' theorem given by
\begin{equation}
\label{eq:stokes_theorem}
\int_M (\grad \wedge A_{n-1})\cdot dX_n = \int_{\partial M} \projection_{\blade{I}_\partial}(A_{n-1}) \cdot dX_{n-1}.
\end{equation}
But this has another, more physical, interpretation. Let us consider the dual relationship by taking vector field $\blade{v}$ and noting that $\blade{v}^\perp$ is an pseudovector for which Stokes' theorem can be applied. Hence,
\begin{equation}
\label{eq:stokes_theorem_dual}
\int_M (\grad \wedge \blade{v}^\perp) \cdot dX_n = \int_{\partial M} \projection_{\blade{I}_\partial}(\blade{v}^\perp) \cdot dX_{n-1},
\end{equation}
which realizes the divergence theorem
\begin{equation}
\int_M \grad \cdot \blade{v} \mu = \int_{\partial M} \blade{v}\cdot \blade{\nu} \mu_\partial.
\end{equation}
Based on Stokes' theorem and the product rule for the exterior derivative, we also have Green's formula
\begin{equation}
\int_M d\alpha_{r-1} \wedge \star \beta_r = \int_M \alpha_{r-1} \wedge \star \delta \beta_r + \int_{\boundary} \iota^* (\alpha_{r-1} \wedge \star \beta_r)
\end{equation}
This equation motivates the definition of \emph{codifferential} $\delta$ as the adjoint to $d$ under the $r$-form inner product. In the case of a closed manifold $M$, $\boundary = \emptyset$ and the boundary integral vanishes, we see that $\delta$ is adjoint to $d$.

\begin{definition}
The adjoint operator $\grad \wedge^*$ to $\grad \wedge$ on $r$-vectors is given by
\begin{equation}
\grad \wedge^* = (-1)^{r-1} (\grad \rfloor A_r^\dagger).
\end{equation}
\end{definition}
This leads to the Hodge-Dirac operator $d+\delta$. One should compare this operator to $\grad$ and notice the subtle differences in the dependence on the manifold dimension and degree of the multivector via both the $(-1)^{r-1}$ term and the application of the reverse $\dagger$.

\begin{proposition}
On multivector equivalents $A_{r-1}$ and $B_r$, we have Green's formula
\begin{equation}
\multivecinnerproduct{\grad \wedge A_{r-1}}{B_r} = \multivecinnerproduct{A_{r-1}}{\grad \wedge^* B_r} + (-1)^{p} \int_{\partial M} (A_{r-1}\rfloor B_r^\dagger) \cdot \blade{\nu} \mu_\partial.
\end{equation}
\end{proposition}
\begin{proof}
First, we have
\begin{equation}
\int_M d(\alpha_{r-1} \wedge \star \beta_r) = \underbrace{\int_M d\alpha_{r-1} \wedge \star \beta_r}_{1} + \underbrace{(-1)^{r-1} \int_M \alpha_{r-1} \wedge d \star \beta_r}_{2},
\end{equation} 
by the Leibniz rule. By Stokes' theorem,
\begin{equation}
\int_M d(\alpha_{r-1} \wedge \star \beta_r) = \underbrace{\int_\boundary \iota^*(\alpha_{r-1} \wedge \star \beta_r)}_{3}.
\end{equation}
For underbrace 1,
\begin{equation}
\int_M d\alpha_{r-1} \wedge \star \beta_r = \int_M (\grad \wedge A_{r-1}) \cdot B_r^\dagger \mu = \multivecinnerproduct{\grad \wedge A_{r-1}}{B_r}.
\end{equation}
For underbrace 2,
\begin{align}
    (-1)^{r-1}\int_M \alpha_{r-1} \wedge d \star \beta_r  &= \int_M A_{r-1} \wedge (\grad \wedge B_r^\star) \cdot dX_n^\dagger\\
    &= (-1)^{r-1+n(n-1)} \int_M [A_{r-1} \wedge (\grad \wedge (B_r^\perp)^\dagger)] \cdot dX_n^\dagger\\
    &= (-1)^{r-1 + \xi} \int_M A_{r-1} \wedge (\grad \rfloor B_r)^\perp \cdot dX_n^\dagger\\
    &= (-1)^{r-1 + \xi} \int_M A_{r-1} \rfloor (\grad \rfloor B_r) \mu\\
    &= \multivecinnerproduct{A_{r-1}}{\grad \wedge^* B_r}.
\end{align}
For underbrace 3,
\begin{align}
\int_\boundary \iota^*(\alpha_{r-1} \wedge \star \beta_r) &= \int_\boundary \projection_{\blade{I}_\partial} (A_{r-1} \wedge B_r^\star) \cdot dX_{n-1}^\dagger\\
&= (-1)^{\xi} \int_\boundary \projection_{\blade{I}_\partial} (A_{r-1} \wedge B_r^\perp) \cdot dX_{n-1}^\dagger\\
&= (-1)^{\xi} \int_\boundary \projection_{\blade{I}_\partial}( (A_{r-1} \rfloor B_r)^\perp) \cdot dX_{n-1}^\dagger\\
&= (-1)^{\xi+p} \int_\boundary (A_{r-1}\rfloor B_r) \cdot \blade{\nu} \mu_\partial 
\end{align}
with the final equality by \cref{prop:flux}.
\end{proof}
\todo{shorten and fix this proof with the new dagger in there.}
Stokes' theorem and Green's formula are essential in determining the $L^2$-orthogonal decomposition of the space of differential $r$-forms $\Omega^r(M)$. The applications thereof provide general existence and uniqueness results for boundary value problems. An analogy of this result can be found next in \cref{subsec:ftgc}. 

\subsection{Fundamental theorem of geometric calculus}
\label{subsec:ftgc}

The containment of the exterior algebra inside a geometric algebra motivates us to push both Stokes' theorem and Green's formula to further limits. Green's formula is derived via Stokes' theorem and both solely make use of the exterior derivative, its adjoint, and the scalar valued Clifford inner product. As it turns out, there is a more general version of Stokes' theorem based on the gradient $\grad$. This theorem turns out to take advantage of the multivector-valued nature of directed integration. Moreover, we pose no restrictions that require single graded elements and we realize that multiple versions exist to the fact that $\grad$ can act on both sides of a multivector.

\begin{theorem}[Fundamental theorems of geometric calculus]
\label{thm:ftga}
Let $A,B\in \G(M)$. Then
\begin{align}
\label{eq:ftga_1}
\int_M \dot{A}\dot{\grad} \blade{I}\mu &= \int_\boundary  A \blade{I}_\partial \mu_\partial\\
\label{eq:ftga_2}
\int_M  \blade{I} \grad B \mu &= \int_\boundary \blade{I}_\partial B \mu_\partial\\
\label{eq:ftga_3}
\int_M  \dot{A}\dot{\grad} \blade{I} B\mu &= (-1)^{n}\int_M A \blade{I} \grad B\mu + \int_\boundary A \blade{I}_\partial B \mu_\partial.
\end{align}
Finally,
\begin{equation}
\label{eq:ftga_4}
\int_M \dot{\sf{L}}(\dot{\grad} \pseudoscalar)\mu = \int_\boundary \sf{L}(\pseudoscalar_\partial)\mu_\partial,
\end{equation}
holds for linear functions $\sf{L}$ of pseudovectors.
\end{theorem}
The above theorem is proved in a handful of texts, but originates via Hestene's work in our go-to reference \cite{hestenes_clifford_1984}. One may question the inclusion of the unit pseudoscalar in equations \cref{eq:ftga_1,eq:ftga_2,eq:ftga_3} and whether they can be pulled outside of the integral. The answer is no, unless $M$ is a region of $\R^n$ since, in that case, the pseudoscalar is constant. In fact, this is used explicitly in the Cauchy integral formula in complex analysis for which we will describe the generalization found in \cref{eq:cauchy_integral}. Note that \cref{eq:ftga_3} is close to describing a multivector valued form of a Green's formula. This is wholeheartedly allowing us to consider consequences of the actions of $\grad$ on both sides of a multivector. In fact, taking the scalar part of \cref{eq:ftga_3} will lead us to the following result.

\begin{theorem}[Multivector Green's formula]
\label{thm:multivector_greens_formula}
We have the Green's formula for the gradient
\begin{equation}
\multivecinnerproduct{\pseudoscalar^{\dagger} A}{\grad B} = (-1)^n \multivecinnerproduct{\grad A}{\pseudoscalar B} + \multivecinnerproduct{A}{\pseudoscalar_\partial B}_\partial.
\end{equation}
\end{theorem}
\begin{proof}
Fix $A^\dagger,B \in \G(M)$ and note \cref{eq:ftga_3} of \cref{thm:ftga} yields
\begin{align}
\int_M A^\dagger \blade{I} \grad B\mu &= (-1)^{n} \int_M \dot{A}^\dagger\dot{\grad} \blade{I} B \mu +  \int_\boundary A^\dagger \blade{I}_\partial B \mu_\partial\\
\int_M A^\dagger \pseudoscalar \grad B \mu &= (-1)^n \int_M (\grad A)^\dagger \pseudoscalar B \mu + \int_\boundary A^\dagger \pseudoscalar_\partial B \mu_\partial.
\end{align}
Now, if we take the scalar part of the above equation and dividing by $\operatorname{vol}(M)$ we have
\begin{align}
\multivecinnerproduct{A}{\pseudoscalar\grad B} &= (-1)^n \multivecinnerproduct{\grad A}{\pseudoscalar B} + \multivecinnerproduct{A}{\pseudoscalar_\partial B}_\partial.
\end{align}

\end{proof}
\begin{remark}
The position of $\pseudoscalar$ and $\pseudoscalar_\partial$ in the above computation is an artifact of choice. Recall \cref{prop:adjoint} and note, for example, that
\begin{equation}
\multivecinnerproduct{A}{\pseudoscalar\grad B} = \multivecinnerproduct{\pseudoscalar^{\dagger}A}{\grad{B}}.
\end{equation}
\end{remark}

Another benefit to this formulation is there was no mention of dependence on the properties of the metric $g$. So, \cref{thm:multivector_greens_formula} holds in spaces with temporal vectors. However, one should remark that we do lose the definiteness of the inner product.


\section{Algebras of multivector fields}

\section{Gelfand theory}




\bibliographystyle{siam}
\bibliography{calderon_problem}





\end{document}
