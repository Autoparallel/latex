\documentclass[leqno]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts}
%\usepackage{fourier}
%\usepackage{heuristica}
\usepackage{enumerate}
\author{Colin Roberts}
\title{MATH 517, Homework 9}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{amsmath}
\usepackage[thmmarks, amsmath, thref]{ntheorem}
%\usepackage{kbordermatrix}
\usepackage{mathtools}
\usepackage{color}

\theoremstyle{nonumberplain}
\theoremheaderfont{\itshape}
\theorembodyfont{\upshape:}
\theoremseparator{.}
\theoremsymbol{\ensuremath{\square}}
\newtheorem{proof}{Proof}
\theoremsymbol{\ensuremath{\square}}
\newtheorem{lemma}{Lemma}
\theoremsymbol{\ensuremath{\blacksquare}}
\newtheorem{solution}{Solution}
\theoremseparator{. ---}
\theoremsymbol{\mbox{\texttt{;o)}}}
\newtheorem{varsol}{Solution (variant)}

\newcommand{\tr}{\mathrm{tr}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\begin{document}
\maketitle
\begin{large}
\begin{center}
Solutions
\end{center}
\end{large}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%PROBLEM%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent\textbf{Problem 1. (Rudin 9.5)} Prove that every $A\in L(\R^n,\R)$ corresponds to a unique $\vec{y} \in \R^n$ so that $A\vec{x} = \vec{x} \cdot \vec{y}$. Also prove that $\|A\|=|\vec{y}|$.

\noindent\rule[0.5ex]{\linewidth}{1pt}

\begin{proof}
Choose the standard orthonormal euclidean basis, and we have a matrix representation of $A$ given by 
\[
A_\beta=
\begin{bmatrix}
A_1\\
A_2\\
\vdots\\
A_2
\end{bmatrix}.
\]

Again (assuming $\vec{x}$ was given in the standard basis) $\vec{x}=\vec{x}_\beta = \begin{bmatrix} x_1,& x_2,& \dots,& x_n \end{bmatrix}$ when written in the standard basis.  We have then that $A_\beta \vec{y}_\beta = A_1x_1+\cdots +A_nx_n$.  So then let $\vec{y}=\begin{bmatrix} A_1, & A_2,& \dots,& A_n \end{bmatrix}$ and we have that $A_\beta \vec{x} = \vec{x}\cdot \vec{y}$. 

To see $\vec{y}$ is unique, consider another vector $\vec{z}$ such that
\begin{align*}
\vec{y}\cdot \vec{x} &= \vec{z}\cdot \vec{x}\\
\iff A_1x_1+\cdots + A_nx_n &= z_1x_1 + \cdots + z_nx_n\\
\iff A_i&=z_i ~~ \forall i.
\end{align*}
So $\vec{y}=\vec{z}$ and we have that $\vec{y}$ is unique.

For the second part of this proof we have that $\|A\|=\sup_{|\vec{x}|=1} |Ax|$.  So
\begin{align*}
\sup_{|\vec{x}|=1} |Ax|= \sup_{|\vec{x}|=1}|\vec{x}\cdot \vec{y}|.\\
\end{align*}
Note that $|\vec{x}\cdot \vec{y}|\leq |x||y|=|y|$, which implies that $\sup_{|\vec{x}|=1}|\vec{x}\cdot \vec{y}|=|\vec{y}|$.
\end{proof}



\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%PROBLEM%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\noindent\textbf{Problem 2. (Rudin 9.6)} Define $f\colon \R^2 \to \R$ by
\[
f(x,y)\coloneqq
\begin{cases}
\frac{xy}{x^2+y^2} & \textrm{if $(x,y)\neq (0,0)$}\\
0 & \textrm{if $(x,y)=(0,0)$.}
\end{cases}
\] 
Prove that $(D_1 f)(x,y)$ and $(D_2 f)(x,y)$ exist at every point of $\R^2$, but that $f$ is not even continuous at $(0,0)$.

\noindent\rule[0.5ex]{\linewidth}{1pt}

\begin{proof}
First, we show that $(D_1 f)(x,y)$ exists at every point of $\R^2$. So consider for $(x,y)\neq (0,0)$
\begin{align*}
(D_1f)(x,y)&=\lim_{t\to 0} \frac{f(x+t,y)-f(x,y)}{t}\\
&= \lim_{t\to 0} \frac{\frac{(x+t)y}{(x+t)^2+y^2}-\frac{xy}{x^2+y^2}}{t}\\
&= \lim_{t\to 0} \frac{1}{t}\left(\frac{xy+ty}{x^2+2tx+y^2}-\frac{xy}{x^2+y^2}\right)\\
&= \lim_{t\to 0} \frac{1}{t} \left( \frac{(x^2+y^2)((xy+ty)-xy(x^2+2tx+y^2)}{(x^2+y^2)(x^2+2tx+y^2)} \right)\\
&= \lim_{t\to 0} \frac{1}{t} \left( \frac{ x^3y+tx^2y+xy^3+ty^3-x^3y-2tx^2y-xy^3}{x^4+2tx^3+2x^2y^2+2txy^2+y^4} \right)\\
&= \lim_{t\to 0} \frac{1}{t} \left( \frac{ tx^2y+ty^3-2tx^2y}{x^4+2tx^3+2x^2y^2+2txy^2+y^4} \right)\\
&= \lim_{t\to 0} \frac{x^2y+y^3-2x^2y}{x^4+2tx^3+2x^2y^2+2txy^2+y^4}\\
&= \frac{x^2y+y^3-2x^2y}{x^4+2x^2y^2+y^4}.
\end{align*}
Now consider $(D_1 f)(0,0)$, which we find by
\begin{align*}
(D_1f)(0,0)&=\lim_{t\to 0} \frac{f(t,0)}{t}\\
&=\lim_{t\to 0} \frac{1}{t}\left(\frac{0}{t^2} \right)\\
&= 0.
\end{align*}
The argument for $(D_2 f)(x,y)$ is exactly analogous.  Just swap $x$ for $y$ in the above proof. Doing this shows that both $(D_1 f)(x,y)$ and $(D_2 f)(x,y)$ exist at each point of $\R^2$.

To see that $f$ is not continuous at $(0,0)$ we do the following:  For a contradiction, assume $f$ is continuous at $(0,0)$ and then $\epsilon=\frac{1}{4}$.  Continuity implies that $\exists \delta>0$ such that $d_{\R^2}((x,y),(0,0))<\delta$ means that $d_{\R}(f(x,y),0)<\epsilon=\frac{1}{4}$.  It follows that
\begin{align*}
\left| \frac{xy}{x^2+y^2} \right| &= \left| \frac{x^2}{2x^2} \right| &&\textrm{letting $x=y$, but forcing $d_{\R^2}((x,x),(0,0))<\delta$}\\
&= \frac{1}{2} >\frac{1}{4}=\epsilon.
\end{align*}
Hence we have a contradiction, and $f$ is not continuous at $(0,0)$.
\end{proof}


\pagebreak


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%PROBLEM%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\noindent\textbf{Problem 3. (Rudin 9.8)} Suppose $E\subseteq \R^n$ is open and that $f\colon E\to \R$ is differentiable on $E$. Prove that if $f$ has a local maximum at $\vec{x}\in E$, then $f'(\vec{x})=0$ (Remember that $0$ here really means the constant linear map that sends everything to $0$).

\noindent\rule[0.5ex]{\linewidth}{1pt}

\begin{proof} 
Since $E$ is open we have that for some $\delta_{i_1}>0$ we have $N(\vec{x},\delta_{i_1})\in E$. Next, define for each $i=1,\dots, n$, the functions $g_i\colon (-\delta_{i_1},\delta_{i_1}) \to \R$ by $g_i(h)=f(\vec{x}+he_i)$ where $e_i$ denotes the $i$th standard orthonormal basis vector.  Note that $g_i(0)=f(\vec{x})$ and thus for each $g_i$ we have $g_i(0)\geq g_i(h)$ for any $h\neq 0 \in (-\delta_{i_1},\delta_{i_1})$.  Since $f$ is differentiable, each partial derivative exists, and we have $\frac{\partial f}{\partial x_i}=\lim_{h\to 0} \frac{g_i(h)-g_i(0)}{h}=g_i'(0)$. By the way $g_i$ is defined, $g_i(0)$ is a local maximum, and by Theorem 5.8 we have that $g_i'(0)=0$.  Of course, this implies that $0=\frac{\partial f}{\partial x_i}(\vec{x})$ since $g_i'(0)=\frac{\partial f}{\partial x_i}(\vec{x})$.  It follows that this is true for each $i=1,\dots, n$ and thus each partial derivative is identically 0 at $\vec{x}$ and this implies that \[f'(\vec{x})=\nabla f(\vec{x})=\left(\frac{\partial f}{\partial x_1},\dots,\frac{\partial f}{\partial x_n}\right)=(0,\dots,0)=0\].  \\

\noindent \textbf{The proof is done above, but I was curious to see if what I have below does work.  If you don't want to read it, I won't be offended! Otherwise it's just checking my intuition.}

(Following from the sentence before I mentioned Theorem 5.8...) Differentiability of $f$ implies $f$ is also continuous and it follows that each $g_i$ is as well. So, for some $h_{i} \in (-\delta_{i_1},0)$ and $h_{i}' \in (0,\delta_{i_1})$ we have that $g_i(h_{i})=g_i(h_{i}')$. Consider then a sequence $\{\delta_{i_j}\}_{j\in \N}$ that converges monotonically to $0$ and has $\delta_{i_1}$ defined as above.  Certainly for each $\delta_{i_j}$ we have an $h_{i_j}\in (-\delta_{i_j},0)$ and $h_{i_j}'\in (0,\delta_{i_j})$ satisfying $g_i(h_{i_j})=g_i(h_{i_j})$. By the mean value theorem applied to $h_{i_j}$ and $h_{i_j}'$, we have that for each $j$ there exists a point $c_j$ such that $g_i'(c_j)=0$. Note that $(-\delta_{i_j},\delta_{i_j})$ converges to $\{0\}$ which implies that the sequence $\{c_j\}_{j\in \N}$ converges to $\{0\}$ as well.  Hence, $g_i'(0)=\frac{\partial f}{\partial x_i}(\vec{x})=0$.  This is true for each $i$ as well and since each partial derivative is $0$ at $\vec{x}$, we have that $f'(\vec{x})=\nabla f(\vec{x})=0$.

\end{proof}
\pagebreak



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%PROBLEM%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\noindent\textbf{Problem 4. (Rudin 9.13)} Suppose $f\colon \R \to \R^3$ is differentiable, and that $|f(t)|=1$ for every $t\in \R$. Explain why $f'(t)$ can be interpreted as an element of $\R^3$ for each $t$, and prove that $f'(t)\cdot f(t)=0$ for all $t$. Interpret this result geometrically.

\noindent\rule[0.5ex]{\linewidth}{1pt}

\begin{proof}
First, $f'(t)$ is defined to be the unique linear map that satisfies
\begin{align*}
\lim_{h\to 0} \frac{|f(t+h)-f(t)-f'(t)h|}{|h|}=0.
\end{align*}
The numerator is vector substraction of elements in $\R^3$ and $h\in \R$, which means that $f'(t)\in \R^3$.  

Now, given $|f(t)|=1$ we have that $f(t)\cdot f(t)=1$ as well.  Then, taking the derivative of both sides,
\begin{align*}
&D(f(t)\cdot f(t))= 0\\
&\iff D\left( \sum_{i=1}^3 f_i(t)f_i(t)\right)=0\\
&\iff \sum_{i=1}^3 \frac{d}{dt} (f_i(t)f_i(t)) =0\\
&\iff \sum_{i=1}^3 (f_i'(t)f_i(t)+f_i(t)f_i'(t))=0\\
&\iff 2 \sum_{i=1}^3 f_i'(t)f_i(t) =0\\
&\iff 2 f'(t)\cdot f(t)=0\\
&\iff f'(t)\cdot f(t) =0.
\end{align*}

Geometrically we are looking at a function that is a curve that lies on the sphere for every $t\in \R$.  When we look at the derivative of $f$, $f'(t)$, we are looking at the tangent vector to the curve.  The tangent plane to the sphere, in which $f'(t)$ lives, is perpendicular to $f(t)$ for every $t$.  In fact, from what I know, $f(t)$ defines the tangent plane in that every vector in the tangent plane is orthogonal to $f(t)$.
\end{proof}


\pagebreak



\end{document}



